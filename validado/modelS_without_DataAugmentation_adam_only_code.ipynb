{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "train_dir = 'train'\n",
    "validation_dir = 'validation'\n",
    "test_dir = 'test'\n",
    "train_airplane_dir = 'train/000_airplane'\n",
    "train_automobile_dir = 'train/001_automobile'\n",
    "train_bird_dir = 'train/002_bird'\n",
    "train_cat_dir = 'train/003_cat'\n",
    "train_deer_dir = 'train/004_deer'\n",
    "train_dog_dir = 'train/005_dog'\n",
    "train_frog_dir = 'train/006_frog'\n",
    "train_horse_dir = 'train/007_horse'\n",
    "train_ship_dir = 'train/008_ship'\n",
    "train_truck_dir = 'train/009_truck'\n",
    "\n",
    "validation_airplane_dir = 'validation/000_airplane'\n",
    "validation_automobile_dir = 'validation/001_automobile'\n",
    "validation_bird_dir = 'validation/002_bird'\n",
    "validation_cat_dir = 'validation/003_cat'\n",
    "validation_deer_dir = 'validation/004_deer'\n",
    "validation_dog_dir = 'validation/005_dog'\n",
    "validation_frog_dir = 'validation/006_frog'\n",
    "validation_horse_dir = 'validation/007_horse'\n",
    "validation_ship_dir = 'validation/008_ship'\n",
    "validation_truck_dir = 'validation/009_truck'\n",
    "\n",
    "test_airplane_dir = 'test/000_airplane'\n",
    "test_automobile_dir = 'test/001_automobile'\n",
    "test_bird_dir = 'test/002_bird'\n",
    "test_cat_dir = 'test/003_cat'\n",
    "test_deer_dir = 'test/004_deer'\n",
    "test_dog_dir = 'test/005_dog'\n",
    "test_frog_dir = 'test/006_frog'\n",
    "test_horse_dir = 'test/007_horse'\n",
    "test_ship_dir = 'test/008_ship'\n",
    "test_truck_dir = 'test/009_truck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "IMG_SIZE = 32\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_batch, labels_batch in train_dataset:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for data_batch, _ in train_dataset.take(1):\n",
    "    for i in range(5):\n",
    "        plt.imshow(data_batch[i].numpy().astype(\"uint8\"))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002622037832120624),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10),\n",
    "    keras.callbacks.ModelCheckpoint(filepath='checkpoint_model_S_without_data_augmentation_adam.keras',save_best_only=True,monitor='val_acc',verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,epochs=50,validation_data=validation_dataset,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "loaded_model = tf.keras.models.load_model('checkpoint_model_S_without_data_augmentation_adam.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = loaded_model.evaluate(validation_dataset)\n",
    "print('val_acc:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_result (result):\n",
    "    for i in range(10):\n",
    "        res = result[0][i].round()\n",
    "        if res == 1:\n",
    "            match i:\n",
    "                case 0:\n",
    "                    print(\"Airplane\")\n",
    "                case 1:\n",
    "                    print(\"Automobile\")\n",
    "                case 2:\n",
    "                    print(\"Bird\")\n",
    "                case 3:\n",
    "                    print(\"Cat\")\n",
    "                case 4:\n",
    "                    print(\"Deer\")\n",
    "                case 5:\n",
    "                    print(\"Dog\")\n",
    "                case 6:\n",
    "                    print(\"Frog\")\n",
    "                case 7:\n",
    "                    print(\"Horse\")\n",
    "                case 8:\n",
    "                    print(\"Ship\")\n",
    "                case 9:\n",
    "                    print(\"Truck\")\n",
    "            return\n",
    "\n",
    "    print(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "img = tf.keras.preprocessing.image.load_img('train/006_frog/alytes_obstetricans_s_000028.png', target_size=(32, 32), interpolation='bilinear')\n",
    "print(img.size)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "print(img_array.shape)\n",
    "result = model.predict(img_array)\n",
    "print(\"Result: \", result.round())\n",
    "class_result(result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
