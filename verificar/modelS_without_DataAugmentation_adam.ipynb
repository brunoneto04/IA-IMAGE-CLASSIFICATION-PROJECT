{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training airplane images: 3995\n",
      "total training automobile images: 4026\n",
      "total training bird images: 3968\n",
      "total training cat images: 3984\n",
      "total training deer images: 4001\n",
      "total training dog images: 4063\n",
      "total training frog images: 3970\n",
      "total training horse images: 3999\n",
      "total training ship images: 3975\n",
      "total training truck images: 4019\n",
      "total validation airplane images: 1005\n",
      "total validation automobile images: 974\n",
      "total validation bird images: 1032\n",
      "total validation cat images: 1016\n",
      "total validation deer images: 999\n",
      "total validation dog images: 937\n",
      "total validation frog images: 1030\n",
      "total validation horse images: 1001\n",
      "total validation ship images: 1025\n",
      "total validation truck images: 981\n",
      "total test airplane images: 1000\n",
      "total test automobile images: 1000\n",
      "total test bird images: 1000\n",
      "total test cat images: 1000\n",
      "total test deer images: 1000\n",
      "total test dog images: 1000\n",
      "total test frog images: 1000\n",
      "total test horse images: 1000\n",
      "total test ship images: 1000\n",
      "total test truck images: 1000\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # or any {‘0’, ‘1’, ‘2’}\n",
    "train_dir = 'train'\n",
    "validation_dir = 'validation'\n",
    "test_dir = 'test'\n",
    "train_airplane_dir = 'train/000_airplane'\n",
    "train_automobile_dir = 'train/001_automobile'\n",
    "train_bird_dir = 'train/002_bird'\n",
    "train_cat_dir = 'train/003_cat'\n",
    "train_deer_dir = 'train/004_deer'\n",
    "train_dog_dir = 'train/005_dog'\n",
    "train_frog_dir = 'train/006_frog'\n",
    "train_horse_dir = 'train/007_horse'\n",
    "train_ship_dir = 'train/008_ship'\n",
    "train_truck_dir = 'train/009_truck'\n",
    "\n",
    "validation_airplane_dir = 'validation/000_airplane'\n",
    "validation_automobile_dir = 'validation/001_automobile'\n",
    "validation_bird_dir = 'validation/002_bird'\n",
    "validation_cat_dir = 'validation/003_cat'\n",
    "validation_deer_dir = 'validation/004_deer'\n",
    "validation_dog_dir = 'validation/005_dog'\n",
    "validation_frog_dir = 'validation/006_frog'\n",
    "validation_horse_dir = 'validation/007_horse'\n",
    "validation_ship_dir = 'validation/008_ship'\n",
    "validation_truck_dir = 'validation/009_truck'\n",
    "\n",
    "test_airplane_dir = 'test/000_airplane'\n",
    "test_automobile_dir = 'test/001_automobile'\n",
    "test_bird_dir = 'test/002_bird'\n",
    "test_cat_dir = 'test/003_cat'\n",
    "test_deer_dir = 'test/004_deer'\n",
    "test_dog_dir = 'test/005_dog'\n",
    "test_frog_dir = 'test/006_frog'\n",
    "test_horse_dir = 'test/007_horse'\n",
    "test_ship_dir = 'test/008_ship'\n",
    "test_truck_dir = 'test/009_truck'\n",
    "\n",
    "\n",
    "print('total training airplane images:', len(os.listdir(train_airplane_dir)))\n",
    "print('total training automobile images:', len(os.listdir(train_automobile_dir)))\n",
    "print('total training bird images:', len(os.listdir(train_bird_dir)))\n",
    "print('total training cat images:', len(os.listdir(train_cat_dir)))\n",
    "print('total training deer images:', len(os.listdir(train_deer_dir)))\n",
    "print('total training dog images:', len(os.listdir(train_dog_dir)))\n",
    "print('total training frog images:', len(os.listdir(train_frog_dir)))\n",
    "print('total training horse images:', len(os.listdir(train_horse_dir)))\n",
    "print('total training ship images:', len(os.listdir(train_ship_dir)))\n",
    "print('total training truck images:', len(os.listdir(train_truck_dir)))\n",
    "\n",
    "print('total validation airplane images:', len(os.listdir(validation_airplane_dir)))\n",
    "print('total validation automobile images:', len(os.listdir(validation_automobile_dir)))\n",
    "print('total validation bird images:', len(os.listdir(validation_bird_dir)))\n",
    "print('total validation cat images:', len(os.listdir(validation_cat_dir)))\n",
    "print('total validation deer images:', len(os.listdir(validation_deer_dir)))\n",
    "print('total validation dog images:', len(os.listdir(validation_dog_dir)))\n",
    "print('total validation frog images:', len(os.listdir(validation_frog_dir)))\n",
    "print('total validation horse images:', len(os.listdir(validation_horse_dir)))\n",
    "print('total validation ship images:', len(os.listdir(validation_ship_dir)))\n",
    "print('total validation truck images:', len(os.listdir(validation_truck_dir)))\n",
    "\n",
    "print('total test airplane images:', len(os.listdir(test_airplane_dir)))\n",
    "print('total test automobile images:', len(os.listdir(test_automobile_dir)))\n",
    "print('total test bird images:', len(os.listdir(test_bird_dir)))\n",
    "print('total test cat images:', len(os.listdir(test_cat_dir)))\n",
    "print('total test deer images:', len(os.listdir(test_deer_dir)))\n",
    "print('total test dog images:', len(os.listdir(test_dog_dir)))\n",
    "print('total test frog images:', len(os.listdir(test_frog_dir)))\n",
    "print('total test horse images:', len(os.listdir(test_horse_dir)))\n",
    "print('total test ship images:', len(os.listdir(test_ship_dir)))\n",
    "print('total test truck images:', len(os.listdir(test_truck_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "IMG_SIZE = 32\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=20)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=20)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 32, 32, 3)\n",
      "labels batch shape: (20, 10)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_dataset:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for data_batch, _ in train_dataset.take(1):\n",
    "    for i in range(5):\n",
    "        plt.imshow(data_batch[i].numpy().astype(\"uint8\"))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "#x = keras.layers.Dropout(0.50)(x)\n",
    "#x = keras.layers.Dropout(0.25)(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,378</span> (665.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m170,378\u001b[0m (665.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,378</span> (665.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m170,378\u001b[0m (665.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=0.1e-4),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10),\n",
    "    keras.callbacks.ModelCheckpoint(filepath='modelS_checkpoint_adam.keras',save_best_only=True,monitor='val_acc',verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718717887.747740  266004 service.cc:145] XLA service 0x7f513800ed50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1718717887.747839  266004 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  33/2000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.1084 - loss: 2.3084  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1718717893.395836  266004 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1013 - loss: 2.3050\n",
      "Epoch 1: val_acc improved from -inf to 0.11870, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - acc: 0.1013 - loss: 2.3050 - val_acc: 0.1187 - val_loss: 2.2943\n",
      "Epoch 2/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.1298 - loss: 2.2811\n",
      "Epoch 2: val_acc improved from 0.11870 to 0.22760, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - acc: 0.1299 - loss: 2.2810 - val_acc: 0.2276 - val_loss: 2.2106\n",
      "Epoch 3/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2061 - loss: 2.1486\n",
      "Epoch 3: val_acc improved from 0.22760 to 0.25620, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - acc: 0.2061 - loss: 2.1484 - val_acc: 0.2562 - val_loss: 2.0588\n",
      "Epoch 4/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2547 - loss: 2.0200\n",
      "Epoch 4: val_acc improved from 0.25620 to 0.28570, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - acc: 0.2547 - loss: 2.0200 - val_acc: 0.2857 - val_loss: 1.9639\n",
      "Epoch 5/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.2921 - loss: 1.9288\n",
      "Epoch 5: val_acc improved from 0.28570 to 0.32250, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.2921 - loss: 1.9287 - val_acc: 0.3225 - val_loss: 1.8833\n",
      "Epoch 6/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3142 - loss: 1.8728\n",
      "Epoch 6: val_acc improved from 0.32250 to 0.34540, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.3142 - loss: 1.8728 - val_acc: 0.3454 - val_loss: 1.8300\n",
      "Epoch 7/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3289 - loss: 1.8270\n",
      "Epoch 7: val_acc improved from 0.34540 to 0.36310, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.3289 - loss: 1.8270 - val_acc: 0.3631 - val_loss: 1.7840\n",
      "Epoch 8/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3400 - loss: 1.7954\n",
      "Epoch 8: val_acc improved from 0.36310 to 0.37110, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.3400 - loss: 1.7954 - val_acc: 0.3711 - val_loss: 1.7499\n",
      "Epoch 9/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3502 - loss: 1.7613\n",
      "Epoch 9: val_acc improved from 0.37110 to 0.37950, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.3502 - loss: 1.7613 - val_acc: 0.3795 - val_loss: 1.7155\n",
      "Epoch 10/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3638 - loss: 1.7285\n",
      "Epoch 10: val_acc improved from 0.37950 to 0.38870, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.3639 - loss: 1.7284 - val_acc: 0.3887 - val_loss: 1.6845\n",
      "Epoch 11/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3734 - loss: 1.6959\n",
      "Epoch 11: val_acc improved from 0.38870 to 0.39900, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.3734 - loss: 1.6959 - val_acc: 0.3990 - val_loss: 1.6543\n",
      "Epoch 12/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3836 - loss: 1.6681\n",
      "Epoch 12: val_acc improved from 0.39900 to 0.40890, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.3836 - loss: 1.6681 - val_acc: 0.4089 - val_loss: 1.6234\n",
      "Epoch 13/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3868 - loss: 1.6473\n",
      "Epoch 13: val_acc improved from 0.40890 to 0.41950, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.3868 - loss: 1.6473 - val_acc: 0.4195 - val_loss: 1.6030\n",
      "Epoch 14/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.3979 - loss: 1.6291\n",
      "Epoch 14: val_acc improved from 0.41950 to 0.42530, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.3979 - loss: 1.6291 - val_acc: 0.4253 - val_loss: 1.5921\n",
      "Epoch 15/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4097 - loss: 1.6027\n",
      "Epoch 15: val_acc improved from 0.42530 to 0.43300, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4097 - loss: 1.6026 - val_acc: 0.4330 - val_loss: 1.5601\n",
      "Epoch 16/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4154 - loss: 1.5848\n",
      "Epoch 16: val_acc improved from 0.43300 to 0.43750, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4154 - loss: 1.5848 - val_acc: 0.4375 - val_loss: 1.5521\n",
      "Epoch 17/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4205 - loss: 1.5683\n",
      "Epoch 17: val_acc improved from 0.43750 to 0.43930, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4205 - loss: 1.5683 - val_acc: 0.4393 - val_loss: 1.5350\n",
      "Epoch 18/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4230 - loss: 1.5562\n",
      "Epoch 18: val_acc improved from 0.43930 to 0.44640, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4230 - loss: 1.5562 - val_acc: 0.4464 - val_loss: 1.5199\n",
      "Epoch 19/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4254 - loss: 1.5510\n",
      "Epoch 19: val_acc improved from 0.44640 to 0.45020, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4254 - loss: 1.5510 - val_acc: 0.4502 - val_loss: 1.5113\n",
      "Epoch 20/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4338 - loss: 1.5346\n",
      "Epoch 20: val_acc improved from 0.45020 to 0.45670, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4338 - loss: 1.5346 - val_acc: 0.4567 - val_loss: 1.4927\n",
      "Epoch 21/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4442 - loss: 1.5174\n",
      "Epoch 21: val_acc improved from 0.45670 to 0.45940, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4442 - loss: 1.5174 - val_acc: 0.4594 - val_loss: 1.4820\n",
      "Epoch 22/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4403 - loss: 1.5108\n",
      "Epoch 22: val_acc improved from 0.45940 to 0.46180, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4403 - loss: 1.5108 - val_acc: 0.4618 - val_loss: 1.4782\n",
      "Epoch 23/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4519 - loss: 1.4999\n",
      "Epoch 23: val_acc improved from 0.46180 to 0.46520, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4519 - loss: 1.4998 - val_acc: 0.4652 - val_loss: 1.4594\n",
      "Epoch 24/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4520 - loss: 1.4983\n",
      "Epoch 24: val_acc improved from 0.46520 to 0.47240, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4520 - loss: 1.4983 - val_acc: 0.4724 - val_loss: 1.4518\n",
      "Epoch 25/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4602 - loss: 1.4843\n",
      "Epoch 25: val_acc improved from 0.47240 to 0.47310, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.4602 - loss: 1.4842 - val_acc: 0.4731 - val_loss: 1.4446\n",
      "Epoch 26/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4572 - loss: 1.4731\n",
      "Epoch 26: val_acc improved from 0.47310 to 0.47580, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.4572 - loss: 1.4731 - val_acc: 0.4758 - val_loss: 1.4362\n",
      "Epoch 27/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4635 - loss: 1.4686\n",
      "Epoch 27: val_acc did not improve from 0.47580\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4635 - loss: 1.4686 - val_acc: 0.4751 - val_loss: 1.4344\n",
      "Epoch 28/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4659 - loss: 1.4603\n",
      "Epoch 28: val_acc improved from 0.47580 to 0.48120, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4659 - loss: 1.4603 - val_acc: 0.4812 - val_loss: 1.4208\n",
      "Epoch 29/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4671 - loss: 1.4474\n",
      "Epoch 29: val_acc improved from 0.48120 to 0.48550, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4671 - loss: 1.4474 - val_acc: 0.4855 - val_loss: 1.4138\n",
      "Epoch 30/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4694 - loss: 1.4474\n",
      "Epoch 30: val_acc improved from 0.48550 to 0.48840, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.4694 - loss: 1.4474 - val_acc: 0.4884 - val_loss: 1.4062\n",
      "Epoch 31/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4786 - loss: 1.4386\n",
      "Epoch 31: val_acc improved from 0.48840 to 0.49030, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4786 - loss: 1.4386 - val_acc: 0.4903 - val_loss: 1.3980\n",
      "Epoch 32/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4800 - loss: 1.4280\n",
      "Epoch 32: val_acc improved from 0.49030 to 0.49090, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4800 - loss: 1.4280 - val_acc: 0.4909 - val_loss: 1.3990\n",
      "Epoch 33/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4809 - loss: 1.4229\n",
      "Epoch 33: val_acc improved from 0.49090 to 0.49750, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4809 - loss: 1.4228 - val_acc: 0.4975 - val_loss: 1.3799\n",
      "Epoch 34/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4849 - loss: 1.4158\n",
      "Epoch 34: val_acc improved from 0.49750 to 0.50090, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4849 - loss: 1.4158 - val_acc: 0.5009 - val_loss: 1.3760\n",
      "Epoch 35/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4867 - loss: 1.4147\n",
      "Epoch 35: val_acc did not improve from 0.50090\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4867 - loss: 1.4146 - val_acc: 0.4979 - val_loss: 1.3747\n",
      "Epoch 36/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4878 - loss: 1.4059\n",
      "Epoch 36: val_acc improved from 0.50090 to 0.50380, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4878 - loss: 1.4059 - val_acc: 0.5038 - val_loss: 1.3637\n",
      "Epoch 37/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4927 - loss: 1.3991\n",
      "Epoch 37: val_acc improved from 0.50380 to 0.50880, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4927 - loss: 1.3991 - val_acc: 0.5088 - val_loss: 1.3546\n",
      "Epoch 38/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4967 - loss: 1.3883\n",
      "Epoch 38: val_acc did not improve from 0.50880\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4967 - loss: 1.3883 - val_acc: 0.5051 - val_loss: 1.3540\n",
      "Epoch 39/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4961 - loss: 1.3877\n",
      "Epoch 39: val_acc improved from 0.50880 to 0.51010, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4961 - loss: 1.3877 - val_acc: 0.5101 - val_loss: 1.3455\n",
      "Epoch 40/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.4970 - loss: 1.3847\n",
      "Epoch 40: val_acc improved from 0.51010 to 0.51310, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.4970 - loss: 1.3846 - val_acc: 0.5131 - val_loss: 1.3377\n",
      "Epoch 41/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5013 - loss: 1.3767\n",
      "Epoch 41: val_acc improved from 0.51310 to 0.51660, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5013 - loss: 1.3767 - val_acc: 0.5166 - val_loss: 1.3318\n",
      "Epoch 42/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5062 - loss: 1.3666\n",
      "Epoch 42: val_acc improved from 0.51660 to 0.51830, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5062 - loss: 1.3666 - val_acc: 0.5183 - val_loss: 1.3267\n",
      "Epoch 43/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5103 - loss: 1.3664\n",
      "Epoch 43: val_acc did not improve from 0.51830\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5103 - loss: 1.3664 - val_acc: 0.5178 - val_loss: 1.3284\n",
      "Epoch 44/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5016 - loss: 1.3644\n",
      "Epoch 44: val_acc improved from 0.51830 to 0.51880, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5016 - loss: 1.3644 - val_acc: 0.5188 - val_loss: 1.3229\n",
      "Epoch 45/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5086 - loss: 1.3568\n",
      "Epoch 45: val_acc improved from 0.51880 to 0.52540, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5086 - loss: 1.3568 - val_acc: 0.5254 - val_loss: 1.3103\n",
      "Epoch 46/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5096 - loss: 1.3490\n",
      "Epoch 46: val_acc improved from 0.52540 to 0.52860, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5096 - loss: 1.3490 - val_acc: 0.5286 - val_loss: 1.3067\n",
      "Epoch 47/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5118 - loss: 1.3434\n",
      "Epoch 47: val_acc did not improve from 0.52860\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5118 - loss: 1.3434 - val_acc: 0.5286 - val_loss: 1.3005\n",
      "Epoch 48/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5154 - loss: 1.3413\n",
      "Epoch 48: val_acc improved from 0.52860 to 0.52970, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5154 - loss: 1.3412 - val_acc: 0.5297 - val_loss: 1.2988\n",
      "Epoch 49/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5151 - loss: 1.3373\n",
      "Epoch 49: val_acc did not improve from 0.52970\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5151 - loss: 1.3373 - val_acc: 0.5272 - val_loss: 1.3031\n",
      "Epoch 50/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5192 - loss: 1.3297\n",
      "Epoch 50: val_acc improved from 0.52970 to 0.53730, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5192 - loss: 1.3297 - val_acc: 0.5373 - val_loss: 1.2825\n",
      "Epoch 51/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5201 - loss: 1.3278\n",
      "Epoch 51: val_acc did not improve from 0.53730\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5201 - loss: 1.3277 - val_acc: 0.5334 - val_loss: 1.2912\n",
      "Epoch 52/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5218 - loss: 1.3246\n",
      "Epoch 52: val_acc did not improve from 0.53730\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.5218 - loss: 1.3246 - val_acc: 0.5372 - val_loss: 1.2828\n",
      "Epoch 53/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5242 - loss: 1.3184\n",
      "Epoch 53: val_acc improved from 0.53730 to 0.54140, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5242 - loss: 1.3183 - val_acc: 0.5414 - val_loss: 1.2744\n",
      "Epoch 54/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5269 - loss: 1.3119\n",
      "Epoch 54: val_acc improved from 0.54140 to 0.54250, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5269 - loss: 1.3119 - val_acc: 0.5425 - val_loss: 1.2702\n",
      "Epoch 55/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5299 - loss: 1.3054\n",
      "Epoch 55: val_acc did not improve from 0.54250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5300 - loss: 1.3054 - val_acc: 0.5411 - val_loss: 1.2733\n",
      "Epoch 56/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5295 - loss: 1.3002\n",
      "Epoch 56: val_acc improved from 0.54250 to 0.54870, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5295 - loss: 1.3002 - val_acc: 0.5487 - val_loss: 1.2568\n",
      "Epoch 57/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5297 - loss: 1.3023\n",
      "Epoch 57: val_acc did not improve from 0.54870\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5297 - loss: 1.3023 - val_acc: 0.5460 - val_loss: 1.2620\n",
      "Epoch 58/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5349 - loss: 1.2965\n",
      "Epoch 58: val_acc improved from 0.54870 to 0.55160, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5349 - loss: 1.2964 - val_acc: 0.5516 - val_loss: 1.2519\n",
      "Epoch 59/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5358 - loss: 1.2896\n",
      "Epoch 59: val_acc did not improve from 0.55160\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5358 - loss: 1.2896 - val_acc: 0.5512 - val_loss: 1.2492\n",
      "Epoch 60/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5369 - loss: 1.2846\n",
      "Epoch 60: val_acc improved from 0.55160 to 0.55430, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5370 - loss: 1.2845 - val_acc: 0.5543 - val_loss: 1.2443\n",
      "Epoch 61/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5353 - loss: 1.2806\n",
      "Epoch 61: val_acc improved from 0.55430 to 0.55930, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.5353 - loss: 1.2806 - val_acc: 0.5593 - val_loss: 1.2348\n",
      "Epoch 62/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5381 - loss: 1.2820\n",
      "Epoch 62: val_acc did not improve from 0.55930\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5381 - loss: 1.2820 - val_acc: 0.5583 - val_loss: 1.2357\n",
      "Epoch 63/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5405 - loss: 1.2745\n",
      "Epoch 63: val_acc improved from 0.55930 to 0.56000, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5405 - loss: 1.2744 - val_acc: 0.5600 - val_loss: 1.2344\n",
      "Epoch 64/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5424 - loss: 1.2708\n",
      "Epoch 64: val_acc improved from 0.56000 to 0.56420, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5424 - loss: 1.2708 - val_acc: 0.5642 - val_loss: 1.2274\n",
      "Epoch 65/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5452 - loss: 1.2659\n",
      "Epoch 65: val_acc improved from 0.56420 to 0.56780, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5452 - loss: 1.2659 - val_acc: 0.5678 - val_loss: 1.2169\n",
      "Epoch 66/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5467 - loss: 1.2613\n",
      "Epoch 66: val_acc did not improve from 0.56780\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5467 - loss: 1.2613 - val_acc: 0.5660 - val_loss: 1.2211\n",
      "Epoch 67/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5508 - loss: 1.2583\n",
      "Epoch 67: val_acc improved from 0.56780 to 0.56850, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.5508 - loss: 1.2583 - val_acc: 0.5685 - val_loss: 1.2158\n",
      "Epoch 68/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5528 - loss: 1.2557\n",
      "Epoch 68: val_acc improved from 0.56850 to 0.57130, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5529 - loss: 1.2557 - val_acc: 0.5713 - val_loss: 1.2064\n",
      "Epoch 69/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5510 - loss: 1.2491\n",
      "Epoch 69: val_acc improved from 0.57130 to 0.57170, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5510 - loss: 1.2491 - val_acc: 0.5717 - val_loss: 1.2098\n",
      "Epoch 70/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5525 - loss: 1.2486\n",
      "Epoch 70: val_acc improved from 0.57170 to 0.57360, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5525 - loss: 1.2485 - val_acc: 0.5736 - val_loss: 1.2021\n",
      "Epoch 71/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5545 - loss: 1.2470\n",
      "Epoch 71: val_acc improved from 0.57360 to 0.57430, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.5546 - loss: 1.2470 - val_acc: 0.5743 - val_loss: 1.1991\n",
      "Epoch 72/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5577 - loss: 1.2404\n",
      "Epoch 72: val_acc improved from 0.57430 to 0.57650, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.5577 - loss: 1.2403 - val_acc: 0.5765 - val_loss: 1.1910\n",
      "Epoch 73/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5538 - loss: 1.2388\n",
      "Epoch 73: val_acc improved from 0.57650 to 0.57920, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5539 - loss: 1.2387 - val_acc: 0.5792 - val_loss: 1.1888\n",
      "Epoch 74/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5525 - loss: 1.2383\n",
      "Epoch 74: val_acc improved from 0.57920 to 0.58290, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5525 - loss: 1.2383 - val_acc: 0.5829 - val_loss: 1.1782\n",
      "Epoch 75/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.5573 - loss: 1.2309\n",
      "Epoch 75: val_acc improved from 0.58290 to 0.58580, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.5573 - loss: 1.2309 - val_acc: 0.5858 - val_loss: 1.1752\n",
      "Epoch 76/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5618 - loss: 1.2259\n",
      "Epoch 76: val_acc did not improve from 0.58580\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.5618 - loss: 1.2259 - val_acc: 0.5842 - val_loss: 1.1770\n",
      "Epoch 77/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5592 - loss: 1.2300\n",
      "Epoch 77: val_acc improved from 0.58580 to 0.58830, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5592 - loss: 1.2299 - val_acc: 0.5883 - val_loss: 1.1681\n",
      "Epoch 78/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5614 - loss: 1.2220\n",
      "Epoch 78: val_acc improved from 0.58830 to 0.58920, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5614 - loss: 1.2220 - val_acc: 0.5892 - val_loss: 1.1629\n",
      "Epoch 79/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5655 - loss: 1.2190\n",
      "Epoch 79: val_acc improved from 0.58920 to 0.59070, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5655 - loss: 1.2190 - val_acc: 0.5907 - val_loss: 1.1644\n",
      "Epoch 80/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5627 - loss: 1.2139\n",
      "Epoch 80: val_acc did not improve from 0.59070\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.5627 - loss: 1.2139 - val_acc: 0.5895 - val_loss: 1.1657\n",
      "Epoch 81/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5670 - loss: 1.2070\n",
      "Epoch 81: val_acc improved from 0.59070 to 0.59200, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5670 - loss: 1.2070 - val_acc: 0.5920 - val_loss: 1.1588\n",
      "Epoch 82/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5664 - loss: 1.2104\n",
      "Epoch 82: val_acc improved from 0.59200 to 0.59550, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.5664 - loss: 1.2104 - val_acc: 0.5955 - val_loss: 1.1519\n",
      "Epoch 83/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5697 - loss: 1.2023\n",
      "Epoch 83: val_acc did not improve from 0.59550\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.5697 - loss: 1.2023 - val_acc: 0.5925 - val_loss: 1.1554\n",
      "Epoch 84/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5721 - loss: 1.2023\n",
      "Epoch 84: val_acc did not improve from 0.59550\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5721 - loss: 1.2023 - val_acc: 0.5939 - val_loss: 1.1531\n",
      "Epoch 85/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5734 - loss: 1.1958\n",
      "Epoch 85: val_acc did not improve from 0.59550\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5734 - loss: 1.1958 - val_acc: 0.5927 - val_loss: 1.1502\n",
      "Epoch 86/1000\n",
      "\u001b[1m1987/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5743 - loss: 1.1908\n",
      "Epoch 86: val_acc improved from 0.59550 to 0.59810, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5743 - loss: 1.1908 - val_acc: 0.5981 - val_loss: 1.1375\n",
      "Epoch 87/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5774 - loss: 1.1923\n",
      "Epoch 87: val_acc did not improve from 0.59810\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - acc: 0.5774 - loss: 1.1922 - val_acc: 0.5980 - val_loss: 1.1373\n",
      "Epoch 88/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5779 - loss: 1.1855\n",
      "Epoch 88: val_acc improved from 0.59810 to 0.59860, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5779 - loss: 1.1855 - val_acc: 0.5986 - val_loss: 1.1363\n",
      "Epoch 89/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5788 - loss: 1.1888\n",
      "Epoch 89: val_acc improved from 0.59860 to 0.60300, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5788 - loss: 1.1888 - val_acc: 0.6030 - val_loss: 1.1241\n",
      "Epoch 90/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5778 - loss: 1.1835\n",
      "Epoch 90: val_acc did not improve from 0.60300\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5778 - loss: 1.1835 - val_acc: 0.6004 - val_loss: 1.1299\n",
      "Epoch 91/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5816 - loss: 1.1780\n",
      "Epoch 91: val_acc did not improve from 0.60300\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5816 - loss: 1.1780 - val_acc: 0.6016 - val_loss: 1.1270\n",
      "Epoch 92/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5812 - loss: 1.1720\n",
      "Epoch 92: val_acc did not improve from 0.60300\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5812 - loss: 1.1720 - val_acc: 0.6029 - val_loss: 1.1265\n",
      "Epoch 93/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5795 - loss: 1.1787\n",
      "Epoch 93: val_acc improved from 0.60300 to 0.60590, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5795 - loss: 1.1787 - val_acc: 0.6059 - val_loss: 1.1205\n",
      "Epoch 94/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5785 - loss: 1.1721\n",
      "Epoch 94: val_acc did not improve from 0.60590\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5785 - loss: 1.1721 - val_acc: 0.6056 - val_loss: 1.1214\n",
      "Epoch 95/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5864 - loss: 1.1633\n",
      "Epoch 95: val_acc improved from 0.60590 to 0.61030, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5864 - loss: 1.1633 - val_acc: 0.6103 - val_loss: 1.1074\n",
      "Epoch 96/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5846 - loss: 1.1665\n",
      "Epoch 96: val_acc improved from 0.61030 to 0.61060, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5846 - loss: 1.1665 - val_acc: 0.6106 - val_loss: 1.1111\n",
      "Epoch 97/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5859 - loss: 1.1587\n",
      "Epoch 97: val_acc did not improve from 0.61060\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5859 - loss: 1.1587 - val_acc: 0.6084 - val_loss: 1.1110\n",
      "Epoch 98/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5877 - loss: 1.1579\n",
      "Epoch 98: val_acc did not improve from 0.61060\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5877 - loss: 1.1579 - val_acc: 0.6085 - val_loss: 1.1075\n",
      "Epoch 99/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5903 - loss: 1.1550\n",
      "Epoch 99: val_acc improved from 0.61060 to 0.61260, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5903 - loss: 1.1550 - val_acc: 0.6126 - val_loss: 1.0996\n",
      "Epoch 100/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5901 - loss: 1.1545\n",
      "Epoch 100: val_acc did not improve from 0.61260\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5901 - loss: 1.1545 - val_acc: 0.6126 - val_loss: 1.1006\n",
      "Epoch 101/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5927 - loss: 1.1456\n",
      "Epoch 101: val_acc improved from 0.61260 to 0.61350, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5927 - loss: 1.1456 - val_acc: 0.6135 - val_loss: 1.0986\n",
      "Epoch 102/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5906 - loss: 1.1480\n",
      "Epoch 102: val_acc improved from 0.61350 to 0.61430, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5906 - loss: 1.1480 - val_acc: 0.6143 - val_loss: 1.0953\n",
      "Epoch 103/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5926 - loss: 1.1479\n",
      "Epoch 103: val_acc improved from 0.61430 to 0.61800, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5926 - loss: 1.1479 - val_acc: 0.6180 - val_loss: 1.0924\n",
      "Epoch 104/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5903 - loss: 1.1490\n",
      "Epoch 104: val_acc did not improve from 0.61800\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5903 - loss: 1.1489 - val_acc: 0.6157 - val_loss: 1.0952\n",
      "Epoch 105/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5964 - loss: 1.1403\n",
      "Epoch 105: val_acc did not improve from 0.61800\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5964 - loss: 1.1403 - val_acc: 0.6172 - val_loss: 1.0901\n",
      "Epoch 106/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5964 - loss: 1.1307\n",
      "Epoch 106: val_acc improved from 0.61800 to 0.61980, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5964 - loss: 1.1307 - val_acc: 0.6198 - val_loss: 1.0856\n",
      "Epoch 107/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5987 - loss: 1.1318\n",
      "Epoch 107: val_acc improved from 0.61980 to 0.62060, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5987 - loss: 1.1317 - val_acc: 0.6206 - val_loss: 1.0813\n",
      "Epoch 108/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5943 - loss: 1.1372\n",
      "Epoch 108: val_acc improved from 0.62060 to 0.62220, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5943 - loss: 1.1372 - val_acc: 0.6222 - val_loss: 1.0818\n",
      "Epoch 109/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5955 - loss: 1.1295\n",
      "Epoch 109: val_acc improved from 0.62220 to 0.62370, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5956 - loss: 1.1294 - val_acc: 0.6237 - val_loss: 1.0736\n",
      "Epoch 110/1000\n",
      "\u001b[1m1987/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5988 - loss: 1.1287\n",
      "Epoch 110: val_acc improved from 0.62370 to 0.62720, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5988 - loss: 1.1286 - val_acc: 0.6272 - val_loss: 1.0705\n",
      "Epoch 111/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5939 - loss: 1.1285\n",
      "Epoch 111: val_acc did not improve from 0.62720\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5940 - loss: 1.1285 - val_acc: 0.6241 - val_loss: 1.0735\n",
      "Epoch 112/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5990 - loss: 1.1251\n",
      "Epoch 112: val_acc did not improve from 0.62720\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5990 - loss: 1.1251 - val_acc: 0.6262 - val_loss: 1.0706\n",
      "Epoch 113/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5993 - loss: 1.1237\n",
      "Epoch 113: val_acc did not improve from 0.62720\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5993 - loss: 1.1237 - val_acc: 0.6250 - val_loss: 1.0724\n",
      "Epoch 114/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6032 - loss: 1.1147\n",
      "Epoch 114: val_acc improved from 0.62720 to 0.62930, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6032 - loss: 1.1147 - val_acc: 0.6293 - val_loss: 1.0637\n",
      "Epoch 115/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6006 - loss: 1.1209\n",
      "Epoch 115: val_acc did not improve from 0.62930\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6006 - loss: 1.1209 - val_acc: 0.6249 - val_loss: 1.0747\n",
      "Epoch 116/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6036 - loss: 1.1135\n",
      "Epoch 116: val_acc did not improve from 0.62930\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6036 - loss: 1.1135 - val_acc: 0.6272 - val_loss: 1.0646\n",
      "Epoch 117/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6050 - loss: 1.1098\n",
      "Epoch 117: val_acc did not improve from 0.62930\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6050 - loss: 1.1098 - val_acc: 0.6290 - val_loss: 1.0625\n",
      "Epoch 118/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.5983 - loss: 1.1170\n",
      "Epoch 118: val_acc improved from 0.62930 to 0.63470, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.5983 - loss: 1.1170 - val_acc: 0.6347 - val_loss: 1.0515\n",
      "Epoch 119/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6057 - loss: 1.1082\n",
      "Epoch 119: val_acc improved from 0.63470 to 0.63720, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6057 - loss: 1.1082 - val_acc: 0.6372 - val_loss: 1.0457\n",
      "Epoch 120/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6104 - loss: 1.1025\n",
      "Epoch 120: val_acc did not improve from 0.63720\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6104 - loss: 1.1025 - val_acc: 0.6335 - val_loss: 1.0502\n",
      "Epoch 121/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6065 - loss: 1.1071\n",
      "Epoch 121: val_acc did not improve from 0.63720\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6065 - loss: 1.1071 - val_acc: 0.6320 - val_loss: 1.0543\n",
      "Epoch 122/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6060 - loss: 1.1042\n",
      "Epoch 122: val_acc did not improve from 0.63720\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6061 - loss: 1.1042 - val_acc: 0.6324 - val_loss: 1.0580\n",
      "Epoch 123/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6095 - loss: 1.1026\n",
      "Epoch 123: val_acc did not improve from 0.63720\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6095 - loss: 1.1026 - val_acc: 0.6358 - val_loss: 1.0430\n",
      "Epoch 124/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6092 - loss: 1.0987\n",
      "Epoch 124: val_acc improved from 0.63720 to 0.63770, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6092 - loss: 1.0987 - val_acc: 0.6377 - val_loss: 1.0419\n",
      "Epoch 125/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6098 - loss: 1.0900\n",
      "Epoch 125: val_acc did not improve from 0.63770\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6098 - loss: 1.0900 - val_acc: 0.6367 - val_loss: 1.0436\n",
      "Epoch 126/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6075 - loss: 1.0927\n",
      "Epoch 126: val_acc did not improve from 0.63770\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6075 - loss: 1.0927 - val_acc: 0.6347 - val_loss: 1.0467\n",
      "Epoch 127/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6150 - loss: 1.0869\n",
      "Epoch 127: val_acc did not improve from 0.63770\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6150 - loss: 1.0869 - val_acc: 0.6374 - val_loss: 1.0377\n",
      "Epoch 128/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6173 - loss: 1.0913\n",
      "Epoch 128: val_acc improved from 0.63770 to 0.63940, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6173 - loss: 1.0913 - val_acc: 0.6394 - val_loss: 1.0362\n",
      "Epoch 129/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6157 - loss: 1.0839\n",
      "Epoch 129: val_acc improved from 0.63940 to 0.64080, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6157 - loss: 1.0839 - val_acc: 0.6408 - val_loss: 1.0326\n",
      "Epoch 130/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6123 - loss: 1.0820\n",
      "Epoch 130: val_acc did not improve from 0.64080\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6123 - loss: 1.0820 - val_acc: 0.6399 - val_loss: 1.0313\n",
      "Epoch 131/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6167 - loss: 1.0818\n",
      "Epoch 131: val_acc improved from 0.64080 to 0.64270, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6167 - loss: 1.0818 - val_acc: 0.6427 - val_loss: 1.0264\n",
      "Epoch 132/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6140 - loss: 1.0830\n",
      "Epoch 132: val_acc improved from 0.64270 to 0.64410, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6140 - loss: 1.0830 - val_acc: 0.6441 - val_loss: 1.0186\n",
      "Epoch 133/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6146 - loss: 1.0757\n",
      "Epoch 133: val_acc did not improve from 0.64410\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6146 - loss: 1.0757 - val_acc: 0.6411 - val_loss: 1.0296\n",
      "Epoch 134/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6176 - loss: 1.0747\n",
      "Epoch 134: val_acc did not improve from 0.64410\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6176 - loss: 1.0747 - val_acc: 0.6441 - val_loss: 1.0186\n",
      "Epoch 135/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6228 - loss: 1.0701\n",
      "Epoch 135: val_acc did not improve from 0.64410\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6228 - loss: 1.0701 - val_acc: 0.6427 - val_loss: 1.0221\n",
      "Epoch 136/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6171 - loss: 1.0701\n",
      "Epoch 136: val_acc did not improve from 0.64410\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6171 - loss: 1.0701 - val_acc: 0.6434 - val_loss: 1.0184\n",
      "Epoch 137/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6168 - loss: 1.0733\n",
      "Epoch 137: val_acc improved from 0.64410 to 0.64480, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6168 - loss: 1.0733 - val_acc: 0.6448 - val_loss: 1.0169\n",
      "Epoch 138/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6209 - loss: 1.0603\n",
      "Epoch 138: val_acc improved from 0.64480 to 0.64710, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6210 - loss: 1.0603 - val_acc: 0.6471 - val_loss: 1.0119\n",
      "Epoch 139/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6182 - loss: 1.0694\n",
      "Epoch 139: val_acc improved from 0.64710 to 0.64810, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6182 - loss: 1.0693 - val_acc: 0.6481 - val_loss: 1.0089\n",
      "Epoch 140/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6173 - loss: 1.0674\n",
      "Epoch 140: val_acc did not improve from 0.64810\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6173 - loss: 1.0673 - val_acc: 0.6463 - val_loss: 1.0095\n",
      "Epoch 141/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6197 - loss: 1.0681\n",
      "Epoch 141: val_acc improved from 0.64810 to 0.64820, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6197 - loss: 1.0681 - val_acc: 0.6482 - val_loss: 1.0109\n",
      "Epoch 142/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6249 - loss: 1.0575\n",
      "Epoch 142: val_acc improved from 0.64820 to 0.64860, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - acc: 0.6249 - loss: 1.0575 - val_acc: 0.6486 - val_loss: 1.0096\n",
      "Epoch 143/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6269 - loss: 1.0534\n",
      "Epoch 143: val_acc did not improve from 0.64860\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6269 - loss: 1.0534 - val_acc: 0.6485 - val_loss: 1.0076\n",
      "Epoch 144/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6273 - loss: 1.0559\n",
      "Epoch 144: val_acc improved from 0.64860 to 0.65030, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6273 - loss: 1.0559 - val_acc: 0.6503 - val_loss: 1.0044\n",
      "Epoch 145/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6235 - loss: 1.0613\n",
      "Epoch 145: val_acc did not improve from 0.65030\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6235 - loss: 1.0613 - val_acc: 0.6497 - val_loss: 1.0051\n",
      "Epoch 146/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.6219 - loss: 1.0577\n",
      "Epoch 146: val_acc improved from 0.65030 to 0.65160, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - acc: 0.6219 - loss: 1.0577 - val_acc: 0.6516 - val_loss: 1.0019\n",
      "Epoch 147/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6235 - loss: 1.0553\n",
      "Epoch 147: val_acc did not improve from 0.65160\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6235 - loss: 1.0553 - val_acc: 0.6512 - val_loss: 1.0024\n",
      "Epoch 148/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6283 - loss: 1.0526\n",
      "Epoch 148: val_acc improved from 0.65160 to 0.65240, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6283 - loss: 1.0526 - val_acc: 0.6524 - val_loss: 0.9959\n",
      "Epoch 149/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6290 - loss: 1.0480\n",
      "Epoch 149: val_acc improved from 0.65240 to 0.65270, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6290 - loss: 1.0480 - val_acc: 0.6527 - val_loss: 0.9991\n",
      "Epoch 150/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6306 - loss: 1.0433\n",
      "Epoch 150: val_acc improved from 0.65270 to 0.65280, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6306 - loss: 1.0433 - val_acc: 0.6528 - val_loss: 0.9980\n",
      "Epoch 151/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6328 - loss: 1.0415\n",
      "Epoch 151: val_acc improved from 0.65280 to 0.65410, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6328 - loss: 1.0415 - val_acc: 0.6541 - val_loss: 0.9881\n",
      "Epoch 152/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6290 - loss: 1.0421\n",
      "Epoch 152: val_acc improved from 0.65410 to 0.65480, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6290 - loss: 1.0421 - val_acc: 0.6548 - val_loss: 0.9911\n",
      "Epoch 153/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6248 - loss: 1.0469\n",
      "Epoch 153: val_acc did not improve from 0.65480\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6248 - loss: 1.0469 - val_acc: 0.6517 - val_loss: 0.9948\n",
      "Epoch 154/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6312 - loss: 1.0400\n",
      "Epoch 154: val_acc improved from 0.65480 to 0.65760, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6312 - loss: 1.0400 - val_acc: 0.6576 - val_loss: 0.9794\n",
      "Epoch 155/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6345 - loss: 1.0338\n",
      "Epoch 155: val_acc did not improve from 0.65760\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6345 - loss: 1.0338 - val_acc: 0.6572 - val_loss: 0.9795\n",
      "Epoch 156/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6308 - loss: 1.0375\n",
      "Epoch 156: val_acc did not improve from 0.65760\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6308 - loss: 1.0375 - val_acc: 0.6555 - val_loss: 0.9856\n",
      "Epoch 157/1000\n",
      "\u001b[1m1987/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6316 - loss: 1.0364\n",
      "Epoch 157: val_acc improved from 0.65760 to 0.65850, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6316 - loss: 1.0364 - val_acc: 0.6585 - val_loss: 0.9815\n",
      "Epoch 158/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6337 - loss: 1.0295\n",
      "Epoch 158: val_acc did not improve from 0.65850\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6337 - loss: 1.0295 - val_acc: 0.6560 - val_loss: 0.9846\n",
      "Epoch 159/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6308 - loss: 1.0332\n",
      "Epoch 159: val_acc did not improve from 0.65850\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6308 - loss: 1.0332 - val_acc: 0.6564 - val_loss: 0.9850\n",
      "Epoch 160/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6321 - loss: 1.0298\n",
      "Epoch 160: val_acc did not improve from 0.65850\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6322 - loss: 1.0298 - val_acc: 0.6580 - val_loss: 0.9823\n",
      "Epoch 161/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6411 - loss: 1.0260\n",
      "Epoch 161: val_acc improved from 0.65850 to 0.66120, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6411 - loss: 1.0260 - val_acc: 0.6612 - val_loss: 0.9757\n",
      "Epoch 162/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6374 - loss: 1.0268\n",
      "Epoch 162: val_acc did not improve from 0.66120\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6374 - loss: 1.0268 - val_acc: 0.6600 - val_loss: 0.9778\n",
      "Epoch 163/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6358 - loss: 1.0284\n",
      "Epoch 163: val_acc did not improve from 0.66120\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6358 - loss: 1.0284 - val_acc: 0.6611 - val_loss: 0.9657\n",
      "Epoch 164/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6372 - loss: 1.0228\n",
      "Epoch 164: val_acc did not improve from 0.66120\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6372 - loss: 1.0228 - val_acc: 0.6600 - val_loss: 0.9762\n",
      "Epoch 165/1000\n",
      "\u001b[1m1987/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6411 - loss: 1.0187\n",
      "Epoch 165: val_acc did not improve from 0.66120\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6411 - loss: 1.0186 - val_acc: 0.6606 - val_loss: 0.9695\n",
      "Epoch 166/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6373 - loss: 1.0193\n",
      "Epoch 166: val_acc improved from 0.66120 to 0.66250, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6373 - loss: 1.0193 - val_acc: 0.6625 - val_loss: 0.9696\n",
      "Epoch 167/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6426 - loss: 1.0182\n",
      "Epoch 167: val_acc did not improve from 0.66250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6426 - loss: 1.0182 - val_acc: 0.6601 - val_loss: 0.9702\n",
      "Epoch 168/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6361 - loss: 1.0195\n",
      "Epoch 168: val_acc improved from 0.66250 to 0.66450, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6361 - loss: 1.0195 - val_acc: 0.6645 - val_loss: 0.9626\n",
      "Epoch 169/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6390 - loss: 1.0165\n",
      "Epoch 169: val_acc did not improve from 0.66450\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6390 - loss: 1.0165 - val_acc: 0.6637 - val_loss: 0.9594\n",
      "Epoch 170/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6413 - loss: 1.0120\n",
      "Epoch 170: val_acc improved from 0.66450 to 0.66480, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6413 - loss: 1.0120 - val_acc: 0.6648 - val_loss: 0.9589\n",
      "Epoch 171/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6442 - loss: 1.0085\n",
      "Epoch 171: val_acc did not improve from 0.66480\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6442 - loss: 1.0085 - val_acc: 0.6634 - val_loss: 0.9607\n",
      "Epoch 172/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6415 - loss: 1.0124\n",
      "Epoch 172: val_acc did not improve from 0.66480\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6415 - loss: 1.0124 - val_acc: 0.6633 - val_loss: 0.9680\n",
      "Epoch 173/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6396 - loss: 1.0119\n",
      "Epoch 173: val_acc did not improve from 0.66480\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6396 - loss: 1.0119 - val_acc: 0.6643 - val_loss: 0.9616\n",
      "Epoch 174/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6442 - loss: 1.0102\n",
      "Epoch 174: val_acc improved from 0.66480 to 0.66670, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6442 - loss: 1.0102 - val_acc: 0.6667 - val_loss: 0.9509\n",
      "Epoch 175/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6410 - loss: 1.0063\n",
      "Epoch 175: val_acc did not improve from 0.66670\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6410 - loss: 1.0063 - val_acc: 0.6645 - val_loss: 0.9599\n",
      "Epoch 176/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6459 - loss: 1.0017\n",
      "Epoch 176: val_acc did not improve from 0.66670\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6459 - loss: 1.0017 - val_acc: 0.6663 - val_loss: 0.9588\n",
      "Epoch 177/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6460 - loss: 1.0021\n",
      "Epoch 177: val_acc improved from 0.66670 to 0.66730, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6460 - loss: 1.0021 - val_acc: 0.6673 - val_loss: 0.9487\n",
      "Epoch 178/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6445 - loss: 1.0017\n",
      "Epoch 178: val_acc did not improve from 0.66730\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6446 - loss: 1.0017 - val_acc: 0.6671 - val_loss: 0.9531\n",
      "Epoch 179/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6445 - loss: 1.0056\n",
      "Epoch 179: val_acc did not improve from 0.66730\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6445 - loss: 1.0056 - val_acc: 0.6660 - val_loss: 0.9541\n",
      "Epoch 180/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6431 - loss: 1.0025\n",
      "Epoch 180: val_acc improved from 0.66730 to 0.66740, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6431 - loss: 1.0025 - val_acc: 0.6674 - val_loss: 0.9508\n",
      "Epoch 181/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6425 - loss: 1.0016\n",
      "Epoch 181: val_acc improved from 0.66740 to 0.66960, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6425 - loss: 1.0016 - val_acc: 0.6696 - val_loss: 0.9422\n",
      "Epoch 182/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6480 - loss: 0.9983\n",
      "Epoch 182: val_acc improved from 0.66960 to 0.67030, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6480 - loss: 0.9983 - val_acc: 0.6703 - val_loss: 0.9499\n",
      "Epoch 183/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6503 - loss: 0.9920\n",
      "Epoch 183: val_acc did not improve from 0.67030\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6503 - loss: 0.9920 - val_acc: 0.6688 - val_loss: 0.9471\n",
      "Epoch 184/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6435 - loss: 0.9981\n",
      "Epoch 184: val_acc improved from 0.67030 to 0.67160, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6435 - loss: 0.9981 - val_acc: 0.6716 - val_loss: 0.9439\n",
      "Epoch 185/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6449 - loss: 0.9897\n",
      "Epoch 185: val_acc did not improve from 0.67160\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6449 - loss: 0.9897 - val_acc: 0.6704 - val_loss: 0.9423\n",
      "Epoch 186/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6500 - loss: 0.9929\n",
      "Epoch 186: val_acc improved from 0.67160 to 0.67220, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6500 - loss: 0.9929 - val_acc: 0.6722 - val_loss: 0.9347\n",
      "Epoch 187/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6490 - loss: 0.9889\n",
      "Epoch 187: val_acc improved from 0.67220 to 0.67230, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6490 - loss: 0.9889 - val_acc: 0.6723 - val_loss: 0.9389\n",
      "Epoch 188/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6467 - loss: 0.9898\n",
      "Epoch 188: val_acc improved from 0.67230 to 0.67360, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6468 - loss: 0.9897 - val_acc: 0.6736 - val_loss: 0.9343\n",
      "Epoch 189/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6480 - loss: 0.9858\n",
      "Epoch 189: val_acc did not improve from 0.67360\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6480 - loss: 0.9858 - val_acc: 0.6700 - val_loss: 0.9414\n",
      "Epoch 190/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6478 - loss: 0.9890\n",
      "Epoch 190: val_acc did not improve from 0.67360\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6478 - loss: 0.9889 - val_acc: 0.6709 - val_loss: 0.9378\n",
      "Epoch 191/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6481 - loss: 0.9843\n",
      "Epoch 191: val_acc did not improve from 0.67360\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6481 - loss: 0.9842 - val_acc: 0.6712 - val_loss: 0.9345\n",
      "Epoch 192/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6546 - loss: 0.9761\n",
      "Epoch 192: val_acc did not improve from 0.67360\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6546 - loss: 0.9760 - val_acc: 0.6705 - val_loss: 0.9365\n",
      "Epoch 193/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6541 - loss: 0.9816\n",
      "Epoch 193: val_acc did not improve from 0.67360\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - acc: 0.6541 - loss: 0.9816 - val_acc: 0.6729 - val_loss: 0.9332\n",
      "Epoch 194/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6547 - loss: 0.9774\n",
      "Epoch 194: val_acc improved from 0.67360 to 0.67540, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6547 - loss: 0.9774 - val_acc: 0.6754 - val_loss: 0.9238\n",
      "Epoch 195/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6498 - loss: 0.9797\n",
      "Epoch 195: val_acc did not improve from 0.67540\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6498 - loss: 0.9797 - val_acc: 0.6730 - val_loss: 0.9330\n",
      "Epoch 196/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6506 - loss: 0.9766\n",
      "Epoch 196: val_acc improved from 0.67540 to 0.67590, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6506 - loss: 0.9766 - val_acc: 0.6759 - val_loss: 0.9237\n",
      "Epoch 197/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6533 - loss: 0.9778\n",
      "Epoch 197: val_acc did not improve from 0.67590\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6533 - loss: 0.9778 - val_acc: 0.6747 - val_loss: 0.9294\n",
      "Epoch 198/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6556 - loss: 0.9681\n",
      "Epoch 198: val_acc did not improve from 0.67590\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6557 - loss: 0.9681 - val_acc: 0.6741 - val_loss: 0.9320\n",
      "Epoch 199/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6525 - loss: 0.9724\n",
      "Epoch 199: val_acc did not improve from 0.67590\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6525 - loss: 0.9724 - val_acc: 0.6749 - val_loss: 0.9260\n",
      "Epoch 200/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6582 - loss: 0.9704\n",
      "Epoch 200: val_acc did not improve from 0.67590\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6582 - loss: 0.9704 - val_acc: 0.6752 - val_loss: 0.9242\n",
      "Epoch 201/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6536 - loss: 0.9707\n",
      "Epoch 201: val_acc did not improve from 0.67590\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6536 - loss: 0.9707 - val_acc: 0.6738 - val_loss: 0.9253\n",
      "Epoch 202/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6516 - loss: 0.9765\n",
      "Epoch 202: val_acc did not improve from 0.67590\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6516 - loss: 0.9765 - val_acc: 0.6752 - val_loss: 0.9236\n",
      "Epoch 203/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6600 - loss: 0.9676\n",
      "Epoch 203: val_acc did not improve from 0.67590\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6600 - loss: 0.9676 - val_acc: 0.6742 - val_loss: 0.9236\n",
      "Epoch 204/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6579 - loss: 0.9661\n",
      "Epoch 204: val_acc improved from 0.67590 to 0.67650, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6579 - loss: 0.9661 - val_acc: 0.6765 - val_loss: 0.9238\n",
      "Epoch 205/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6607 - loss: 0.9627\n",
      "Epoch 205: val_acc improved from 0.67650 to 0.67870, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6607 - loss: 0.9627 - val_acc: 0.6787 - val_loss: 0.9121\n",
      "Epoch 206/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6599 - loss: 0.9629\n",
      "Epoch 206: val_acc did not improve from 0.67870\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6599 - loss: 0.9629 - val_acc: 0.6774 - val_loss: 0.9160\n",
      "Epoch 207/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6571 - loss: 0.9578\n",
      "Epoch 207: val_acc did not improve from 0.67870\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6571 - loss: 0.9578 - val_acc: 0.6780 - val_loss: 0.9153\n",
      "Epoch 208/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6592 - loss: 0.9632\n",
      "Epoch 208: val_acc improved from 0.67870 to 0.67920, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6592 - loss: 0.9632 - val_acc: 0.6792 - val_loss: 0.9136\n",
      "Epoch 209/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6595 - loss: 0.9620\n",
      "Epoch 209: val_acc improved from 0.67920 to 0.68080, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6595 - loss: 0.9619 - val_acc: 0.6808 - val_loss: 0.9078\n",
      "Epoch 210/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6576 - loss: 0.9602\n",
      "Epoch 210: val_acc did not improve from 0.68080\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6576 - loss: 0.9602 - val_acc: 0.6783 - val_loss: 0.9191\n",
      "Epoch 211/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6633 - loss: 0.9536\n",
      "Epoch 211: val_acc did not improve from 0.68080\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6633 - loss: 0.9536 - val_acc: 0.6800 - val_loss: 0.9132\n",
      "Epoch 212/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6616 - loss: 0.9562\n",
      "Epoch 212: val_acc did not improve from 0.68080\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6616 - loss: 0.9562 - val_acc: 0.6808 - val_loss: 0.9095\n",
      "Epoch 213/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6626 - loss: 0.9554\n",
      "Epoch 213: val_acc did not improve from 0.68080\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6626 - loss: 0.9554 - val_acc: 0.6802 - val_loss: 0.9114\n",
      "Epoch 214/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6630 - loss: 0.9514\n",
      "Epoch 214: val_acc improved from 0.68080 to 0.68150, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6630 - loss: 0.9514 - val_acc: 0.6815 - val_loss: 0.9033\n",
      "Epoch 215/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6622 - loss: 0.9534\n",
      "Epoch 215: val_acc did not improve from 0.68150\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6622 - loss: 0.9534 - val_acc: 0.6810 - val_loss: 0.9035\n",
      "Epoch 216/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6641 - loss: 0.9521\n",
      "Epoch 216: val_acc did not improve from 0.68150\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6641 - loss: 0.9521 - val_acc: 0.6806 - val_loss: 0.9096\n",
      "Epoch 217/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6640 - loss: 0.9478\n",
      "Epoch 217: val_acc did not improve from 0.68150\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6640 - loss: 0.9478 - val_acc: 0.6808 - val_loss: 0.9085\n",
      "Epoch 218/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6624 - loss: 0.9506\n",
      "Epoch 218: val_acc improved from 0.68150 to 0.68270, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6624 - loss: 0.9506 - val_acc: 0.6827 - val_loss: 0.9049\n",
      "Epoch 219/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6632 - loss: 0.9531\n",
      "Epoch 219: val_acc improved from 0.68270 to 0.68320, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6632 - loss: 0.9531 - val_acc: 0.6832 - val_loss: 0.9052\n",
      "Epoch 220/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6658 - loss: 0.9452\n",
      "Epoch 220: val_acc improved from 0.68320 to 0.68390, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6658 - loss: 0.9452 - val_acc: 0.6839 - val_loss: 0.9069\n",
      "Epoch 221/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6643 - loss: 0.9471\n",
      "Epoch 221: val_acc improved from 0.68390 to 0.68400, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6643 - loss: 0.9471 - val_acc: 0.6840 - val_loss: 0.9014\n",
      "Epoch 222/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6632 - loss: 0.9482\n",
      "Epoch 222: val_acc did not improve from 0.68400\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6632 - loss: 0.9482 - val_acc: 0.6836 - val_loss: 0.9043\n",
      "Epoch 223/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6675 - loss: 0.9396\n",
      "Epoch 223: val_acc improved from 0.68400 to 0.68650, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6675 - loss: 0.9396 - val_acc: 0.6865 - val_loss: 0.8960\n",
      "Epoch 224/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6658 - loss: 0.9391\n",
      "Epoch 224: val_acc did not improve from 0.68650\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6658 - loss: 0.9391 - val_acc: 0.6859 - val_loss: 0.8928\n",
      "Epoch 225/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6685 - loss: 0.9448\n",
      "Epoch 225: val_acc did not improve from 0.68650\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6685 - loss: 0.9448 - val_acc: 0.6849 - val_loss: 0.8986\n",
      "Epoch 226/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6679 - loss: 0.9335\n",
      "Epoch 226: val_acc improved from 0.68650 to 0.68690, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6679 - loss: 0.9335 - val_acc: 0.6869 - val_loss: 0.8941\n",
      "Epoch 227/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6689 - loss: 0.9389\n",
      "Epoch 227: val_acc improved from 0.68690 to 0.68810, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6689 - loss: 0.9389 - val_acc: 0.6881 - val_loss: 0.8872\n",
      "Epoch 228/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6675 - loss: 0.9392\n",
      "Epoch 228: val_acc did not improve from 0.68810\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6675 - loss: 0.9392 - val_acc: 0.6874 - val_loss: 0.8909\n",
      "Epoch 229/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6668 - loss: 0.9386\n",
      "Epoch 229: val_acc improved from 0.68810 to 0.68910, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6668 - loss: 0.9386 - val_acc: 0.6891 - val_loss: 0.8841\n",
      "Epoch 230/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6684 - loss: 0.9334\n",
      "Epoch 230: val_acc did not improve from 0.68910\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6684 - loss: 0.9334 - val_acc: 0.6876 - val_loss: 0.8942\n",
      "Epoch 231/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6698 - loss: 0.9289\n",
      "Epoch 231: val_acc did not improve from 0.68910\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6698 - loss: 0.9289 - val_acc: 0.6870 - val_loss: 0.8984\n",
      "Epoch 232/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6682 - loss: 0.9365\n",
      "Epoch 232: val_acc improved from 0.68910 to 0.69040, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6682 - loss: 0.9365 - val_acc: 0.6904 - val_loss: 0.8862\n",
      "Epoch 233/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6714 - loss: 0.9300\n",
      "Epoch 233: val_acc did not improve from 0.69040\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6714 - loss: 0.9300 - val_acc: 0.6895 - val_loss: 0.8864\n",
      "Epoch 234/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6716 - loss: 0.9303\n",
      "Epoch 234: val_acc did not improve from 0.69040\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6716 - loss: 0.9303 - val_acc: 0.6902 - val_loss: 0.8862\n",
      "Epoch 235/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6741 - loss: 0.9255\n",
      "Epoch 235: val_acc did not improve from 0.69040\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6741 - loss: 0.9255 - val_acc: 0.6890 - val_loss: 0.8872\n",
      "Epoch 236/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6690 - loss: 0.9325\n",
      "Epoch 236: val_acc improved from 0.69040 to 0.69120, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6690 - loss: 0.9324 - val_acc: 0.6912 - val_loss: 0.8810\n",
      "Epoch 237/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6688 - loss: 0.9304\n",
      "Epoch 237: val_acc did not improve from 0.69120\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6688 - loss: 0.9304 - val_acc: 0.6895 - val_loss: 0.8836\n",
      "Epoch 238/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6734 - loss: 0.9241\n",
      "Epoch 238: val_acc did not improve from 0.69120\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6734 - loss: 0.9241 - val_acc: 0.6899 - val_loss: 0.8815\n",
      "Epoch 239/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6731 - loss: 0.9261\n",
      "Epoch 239: val_acc improved from 0.69120 to 0.69200, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6731 - loss: 0.9261 - val_acc: 0.6920 - val_loss: 0.8773\n",
      "Epoch 240/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6728 - loss: 0.9270\n",
      "Epoch 240: val_acc did not improve from 0.69200\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6728 - loss: 0.9270 - val_acc: 0.6918 - val_loss: 0.8794\n",
      "Epoch 241/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6767 - loss: 0.9231\n",
      "Epoch 241: val_acc did not improve from 0.69200\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6767 - loss: 0.9231 - val_acc: 0.6910 - val_loss: 0.8760\n",
      "Epoch 242/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6741 - loss: 0.9211\n",
      "Epoch 242: val_acc improved from 0.69200 to 0.69320, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6741 - loss: 0.9211 - val_acc: 0.6932 - val_loss: 0.8762\n",
      "Epoch 243/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6748 - loss: 0.9199\n",
      "Epoch 243: val_acc improved from 0.69320 to 0.69330, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6748 - loss: 0.9198 - val_acc: 0.6933 - val_loss: 0.8771\n",
      "Epoch 244/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6743 - loss: 0.9211\n",
      "Epoch 244: val_acc improved from 0.69330 to 0.69340, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6743 - loss: 0.9211 - val_acc: 0.6934 - val_loss: 0.8733\n",
      "Epoch 245/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6715 - loss: 0.9183\n",
      "Epoch 245: val_acc did not improve from 0.69340\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6715 - loss: 0.9183 - val_acc: 0.6927 - val_loss: 0.8760\n",
      "Epoch 246/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6737 - loss: 0.9173\n",
      "Epoch 246: val_acc did not improve from 0.69340\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6737 - loss: 0.9173 - val_acc: 0.6920 - val_loss: 0.8783\n",
      "Epoch 247/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6746 - loss: 0.9195\n",
      "Epoch 247: val_acc did not improve from 0.69340\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6746 - loss: 0.9195 - val_acc: 0.6916 - val_loss: 0.8801\n",
      "Epoch 248/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6766 - loss: 0.9157\n",
      "Epoch 248: val_acc improved from 0.69340 to 0.69520, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6766 - loss: 0.9157 - val_acc: 0.6952 - val_loss: 0.8697\n",
      "Epoch 249/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6739 - loss: 0.9174\n",
      "Epoch 249: val_acc did not improve from 0.69520\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6739 - loss: 0.9174 - val_acc: 0.6942 - val_loss: 0.8723\n",
      "Epoch 250/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6740 - loss: 0.9133\n",
      "Epoch 250: val_acc improved from 0.69520 to 0.69750, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6740 - loss: 0.9133 - val_acc: 0.6975 - val_loss: 0.8624\n",
      "Epoch 251/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6752 - loss: 0.9101\n",
      "Epoch 251: val_acc did not improve from 0.69750\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6752 - loss: 0.9101 - val_acc: 0.6960 - val_loss: 0.8705\n",
      "Epoch 252/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6765 - loss: 0.9107\n",
      "Epoch 252: val_acc did not improve from 0.69750\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6765 - loss: 0.9107 - val_acc: 0.6975 - val_loss: 0.8625\n",
      "Epoch 253/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6793 - loss: 0.9086\n",
      "Epoch 253: val_acc did not improve from 0.69750\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6793 - loss: 0.9086 - val_acc: 0.6962 - val_loss: 0.8646\n",
      "Epoch 254/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6805 - loss: 0.9074\n",
      "Epoch 254: val_acc improved from 0.69750 to 0.69760, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6805 - loss: 0.9073 - val_acc: 0.6976 - val_loss: 0.8655\n",
      "Epoch 255/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6787 - loss: 0.9067\n",
      "Epoch 255: val_acc did not improve from 0.69760\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6787 - loss: 0.9067 - val_acc: 0.6952 - val_loss: 0.8688\n",
      "Epoch 256/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6789 - loss: 0.9105\n",
      "Epoch 256: val_acc improved from 0.69760 to 0.69800, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6789 - loss: 0.9105 - val_acc: 0.6980 - val_loss: 0.8584\n",
      "Epoch 257/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6803 - loss: 0.9032\n",
      "Epoch 257: val_acc did not improve from 0.69800\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6803 - loss: 0.9032 - val_acc: 0.6960 - val_loss: 0.8636\n",
      "Epoch 258/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6800 - loss: 0.9028\n",
      "Epoch 258: val_acc did not improve from 0.69800\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6800 - loss: 0.9028 - val_acc: 0.6946 - val_loss: 0.8669\n",
      "Epoch 259/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6831 - loss: 0.8948\n",
      "Epoch 259: val_acc did not improve from 0.69800\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6831 - loss: 0.8949 - val_acc: 0.6977 - val_loss: 0.8608\n",
      "Epoch 260/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6803 - loss: 0.9025\n",
      "Epoch 260: val_acc did not improve from 0.69800\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6803 - loss: 0.9025 - val_acc: 0.6977 - val_loss: 0.8631\n",
      "Epoch 261/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6790 - loss: 0.9094\n",
      "Epoch 261: val_acc improved from 0.69800 to 0.69820, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6790 - loss: 0.9094 - val_acc: 0.6982 - val_loss: 0.8576\n",
      "Epoch 262/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6858 - loss: 0.8981\n",
      "Epoch 262: val_acc did not improve from 0.69820\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6858 - loss: 0.8981 - val_acc: 0.6973 - val_loss: 0.8612\n",
      "Epoch 263/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6799 - loss: 0.9009\n",
      "Epoch 263: val_acc did not improve from 0.69820\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6799 - loss: 0.9009 - val_acc: 0.6962 - val_loss: 0.8622\n",
      "Epoch 264/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6848 - loss: 0.8928\n",
      "Epoch 264: val_acc did not improve from 0.69820\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6848 - loss: 0.8928 - val_acc: 0.6982 - val_loss: 0.8575\n",
      "Epoch 265/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6833 - loss: 0.9012\n",
      "Epoch 265: val_acc improved from 0.69820 to 0.69880, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6833 - loss: 0.9012 - val_acc: 0.6988 - val_loss: 0.8568\n",
      "Epoch 266/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6848 - loss: 0.8932\n",
      "Epoch 266: val_acc did not improve from 0.69880\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6848 - loss: 0.8932 - val_acc: 0.6988 - val_loss: 0.8581\n",
      "Epoch 267/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6803 - loss: 0.8949\n",
      "Epoch 267: val_acc did not improve from 0.69880\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6803 - loss: 0.8949 - val_acc: 0.6987 - val_loss: 0.8560\n",
      "Epoch 268/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6850 - loss: 0.8935\n",
      "Epoch 268: val_acc did not improve from 0.69880\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6850 - loss: 0.8935 - val_acc: 0.6987 - val_loss: 0.8542\n",
      "Epoch 269/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6821 - loss: 0.8978\n",
      "Epoch 269: val_acc improved from 0.69880 to 0.69970, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6821 - loss: 0.8978 - val_acc: 0.6997 - val_loss: 0.8538\n",
      "Epoch 270/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6848 - loss: 0.8905\n",
      "Epoch 270: val_acc improved from 0.69970 to 0.70090, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6848 - loss: 0.8905 - val_acc: 0.7009 - val_loss: 0.8459\n",
      "Epoch 271/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6827 - loss: 0.8973\n",
      "Epoch 271: val_acc did not improve from 0.70090\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6827 - loss: 0.8973 - val_acc: 0.6997 - val_loss: 0.8519\n",
      "Epoch 272/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6853 - loss: 0.8855\n",
      "Epoch 272: val_acc improved from 0.70090 to 0.70510, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6853 - loss: 0.8855 - val_acc: 0.7051 - val_loss: 0.8430\n",
      "Epoch 273/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6835 - loss: 0.8865\n",
      "Epoch 273: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6835 - loss: 0.8865 - val_acc: 0.7025 - val_loss: 0.8497\n",
      "Epoch 274/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6846 - loss: 0.8902\n",
      "Epoch 274: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6846 - loss: 0.8902 - val_acc: 0.6980 - val_loss: 0.8557\n",
      "Epoch 275/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6849 - loss: 0.8857\n",
      "Epoch 275: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6849 - loss: 0.8857 - val_acc: 0.6995 - val_loss: 0.8509\n",
      "Epoch 276/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6819 - loss: 0.8882\n",
      "Epoch 276: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6819 - loss: 0.8882 - val_acc: 0.7020 - val_loss: 0.8502\n",
      "Epoch 277/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6858 - loss: 0.8876\n",
      "Epoch 277: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6858 - loss: 0.8876 - val_acc: 0.7023 - val_loss: 0.8443\n",
      "Epoch 278/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6871 - loss: 0.8882\n",
      "Epoch 278: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6871 - loss: 0.8882 - val_acc: 0.7024 - val_loss: 0.8438\n",
      "Epoch 279/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6864 - loss: 0.8802\n",
      "Epoch 279: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6864 - loss: 0.8802 - val_acc: 0.7034 - val_loss: 0.8458\n",
      "Epoch 280/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6860 - loss: 0.8815\n",
      "Epoch 280: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6860 - loss: 0.8815 - val_acc: 0.7012 - val_loss: 0.8472\n",
      "Epoch 281/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6852 - loss: 0.8849\n",
      "Epoch 281: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6852 - loss: 0.8849 - val_acc: 0.7051 - val_loss: 0.8395\n",
      "Epoch 282/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6855 - loss: 0.8815\n",
      "Epoch 282: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6855 - loss: 0.8815 - val_acc: 0.7035 - val_loss: 0.8415\n",
      "Epoch 283/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6892 - loss: 0.8823\n",
      "Epoch 283: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6892 - loss: 0.8823 - val_acc: 0.7047 - val_loss: 0.8361\n",
      "Epoch 284/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6909 - loss: 0.8751\n",
      "Epoch 284: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6909 - loss: 0.8751 - val_acc: 0.7047 - val_loss: 0.8453\n",
      "Epoch 285/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6913 - loss: 0.8753\n",
      "Epoch 285: val_acc did not improve from 0.70510\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6913 - loss: 0.8753 - val_acc: 0.7040 - val_loss: 0.8450\n",
      "Epoch 286/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6895 - loss: 0.8715\n",
      "Epoch 286: val_acc improved from 0.70510 to 0.70560, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6895 - loss: 0.8715 - val_acc: 0.7056 - val_loss: 0.8364\n",
      "Epoch 287/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6891 - loss: 0.8711\n",
      "Epoch 287: val_acc did not improve from 0.70560\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6891 - loss: 0.8711 - val_acc: 0.7043 - val_loss: 0.8372\n",
      "Epoch 288/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6846 - loss: 0.8851\n",
      "Epoch 288: val_acc did not improve from 0.70560\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6847 - loss: 0.8850 - val_acc: 0.7052 - val_loss: 0.8349\n",
      "Epoch 289/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.6898 - loss: 0.8745\n",
      "Epoch 289: val_acc did not improve from 0.70560\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6898 - loss: 0.8744 - val_acc: 0.7049 - val_loss: 0.8332\n",
      "Epoch 290/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6897 - loss: 0.8732\n",
      "Epoch 290: val_acc improved from 0.70560 to 0.70660, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6897 - loss: 0.8732 - val_acc: 0.7066 - val_loss: 0.8339\n",
      "Epoch 291/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6932 - loss: 0.8706\n",
      "Epoch 291: val_acc improved from 0.70660 to 0.70670, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6933 - loss: 0.8706 - val_acc: 0.7067 - val_loss: 0.8309\n",
      "Epoch 292/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6905 - loss: 0.8702\n",
      "Epoch 292: val_acc improved from 0.70670 to 0.70780, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6906 - loss: 0.8702 - val_acc: 0.7078 - val_loss: 0.8325\n",
      "Epoch 293/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6917 - loss: 0.8730\n",
      "Epoch 293: val_acc did not improve from 0.70780\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6917 - loss: 0.8729 - val_acc: 0.7074 - val_loss: 0.8342\n",
      "Epoch 294/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6895 - loss: 0.8761\n",
      "Epoch 294: val_acc did not improve from 0.70780\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6895 - loss: 0.8761 - val_acc: 0.7048 - val_loss: 0.8380\n",
      "Epoch 295/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6920 - loss: 0.8710\n",
      "Epoch 295: val_acc improved from 0.70780 to 0.70930, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6920 - loss: 0.8710 - val_acc: 0.7093 - val_loss: 0.8246\n",
      "Epoch 296/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6945 - loss: 0.8608\n",
      "Epoch 296: val_acc did not improve from 0.70930\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6945 - loss: 0.8608 - val_acc: 0.7058 - val_loss: 0.8328\n",
      "Epoch 297/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6945 - loss: 0.8671\n",
      "Epoch 297: val_acc did not improve from 0.70930\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6945 - loss: 0.8671 - val_acc: 0.7077 - val_loss: 0.8288\n",
      "Epoch 298/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6928 - loss: 0.8652\n",
      "Epoch 298: val_acc did not improve from 0.70930\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6928 - loss: 0.8652 - val_acc: 0.7061 - val_loss: 0.8281\n",
      "Epoch 299/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6934 - loss: 0.8690\n",
      "Epoch 299: val_acc did not improve from 0.70930\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6934 - loss: 0.8690 - val_acc: 0.7078 - val_loss: 0.8269\n",
      "Epoch 300/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6945 - loss: 0.8639\n",
      "Epoch 300: val_acc improved from 0.70930 to 0.71120, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6945 - loss: 0.8639 - val_acc: 0.7112 - val_loss: 0.8205\n",
      "Epoch 301/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6936 - loss: 0.8620\n",
      "Epoch 301: val_acc did not improve from 0.71120\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6936 - loss: 0.8620 - val_acc: 0.7077 - val_loss: 0.8256\n",
      "Epoch 302/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6922 - loss: 0.8640\n",
      "Epoch 302: val_acc did not improve from 0.71120\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6922 - loss: 0.8640 - val_acc: 0.7098 - val_loss: 0.8211\n",
      "Epoch 303/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6954 - loss: 0.8617\n",
      "Epoch 303: val_acc did not improve from 0.71120\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6954 - loss: 0.8617 - val_acc: 0.7099 - val_loss: 0.8252\n",
      "Epoch 304/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6935 - loss: 0.8603\n",
      "Epoch 304: val_acc did not improve from 0.71120\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6935 - loss: 0.8603 - val_acc: 0.7078 - val_loss: 0.8280\n",
      "Epoch 305/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6934 - loss: 0.8624\n",
      "Epoch 305: val_acc did not improve from 0.71120\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6934 - loss: 0.8624 - val_acc: 0.7098 - val_loss: 0.8204\n",
      "Epoch 306/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6941 - loss: 0.8581\n",
      "Epoch 306: val_acc improved from 0.71120 to 0.71400, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6941 - loss: 0.8581 - val_acc: 0.7140 - val_loss: 0.8156\n",
      "Epoch 307/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6960 - loss: 0.8635\n",
      "Epoch 307: val_acc did not improve from 0.71400\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6960 - loss: 0.8634 - val_acc: 0.7116 - val_loss: 0.8198\n",
      "Epoch 308/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6958 - loss: 0.8539\n",
      "Epoch 308: val_acc did not improve from 0.71400\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6958 - loss: 0.8538 - val_acc: 0.7119 - val_loss: 0.8175\n",
      "Epoch 309/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6950 - loss: 0.8523\n",
      "Epoch 309: val_acc did not improve from 0.71400\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6950 - loss: 0.8523 - val_acc: 0.7113 - val_loss: 0.8238\n",
      "Epoch 310/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6929 - loss: 0.8605\n",
      "Epoch 310: val_acc did not improve from 0.71400\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6929 - loss: 0.8605 - val_acc: 0.7113 - val_loss: 0.8193\n",
      "Epoch 311/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6958 - loss: 0.8480\n",
      "Epoch 311: val_acc did not improve from 0.71400\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6958 - loss: 0.8480 - val_acc: 0.7131 - val_loss: 0.8155\n",
      "Epoch 312/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6925 - loss: 0.8528\n",
      "Epoch 312: val_acc did not improve from 0.71400\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6925 - loss: 0.8528 - val_acc: 0.7106 - val_loss: 0.8179\n",
      "Epoch 313/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6975 - loss: 0.8504\n",
      "Epoch 313: val_acc improved from 0.71400 to 0.71530, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6976 - loss: 0.8503 - val_acc: 0.7153 - val_loss: 0.8076\n",
      "Epoch 314/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6936 - loss: 0.8560\n",
      "Epoch 314: val_acc did not improve from 0.71530\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6936 - loss: 0.8560 - val_acc: 0.7139 - val_loss: 0.8098\n",
      "Epoch 315/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7009 - loss: 0.8536\n",
      "Epoch 315: val_acc did not improve from 0.71530\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7009 - loss: 0.8536 - val_acc: 0.7127 - val_loss: 0.8134\n",
      "Epoch 316/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7003 - loss: 0.8437\n",
      "Epoch 316: val_acc did not improve from 0.71530\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7003 - loss: 0.8437 - val_acc: 0.7125 - val_loss: 0.8081\n",
      "Epoch 317/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6993 - loss: 0.8480\n",
      "Epoch 317: val_acc did not improve from 0.71530\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.6993 - loss: 0.8479 - val_acc: 0.7145 - val_loss: 0.8093\n",
      "Epoch 318/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7009 - loss: 0.8476\n",
      "Epoch 318: val_acc did not improve from 0.71530\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7009 - loss: 0.8476 - val_acc: 0.7137 - val_loss: 0.8112\n",
      "Epoch 319/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7006 - loss: 0.8412\n",
      "Epoch 319: val_acc did not improve from 0.71530\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7006 - loss: 0.8412 - val_acc: 0.7139 - val_loss: 0.8116\n",
      "Epoch 320/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7029 - loss: 0.8465\n",
      "Epoch 320: val_acc improved from 0.71530 to 0.71740, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7029 - loss: 0.8465 - val_acc: 0.7174 - val_loss: 0.8071\n",
      "Epoch 321/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7024 - loss: 0.8437\n",
      "Epoch 321: val_acc did not improve from 0.71740\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7024 - loss: 0.8437 - val_acc: 0.7123 - val_loss: 0.8188\n",
      "Epoch 322/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7003 - loss: 0.8477\n",
      "Epoch 322: val_acc did not improve from 0.71740\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7003 - loss: 0.8477 - val_acc: 0.7136 - val_loss: 0.8104\n",
      "Epoch 323/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7032 - loss: 0.8463\n",
      "Epoch 323: val_acc did not improve from 0.71740\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7032 - loss: 0.8463 - val_acc: 0.7145 - val_loss: 0.8097\n",
      "Epoch 324/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7030 - loss: 0.8410\n",
      "Epoch 324: val_acc improved from 0.71740 to 0.71760, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7030 - loss: 0.8410 - val_acc: 0.7176 - val_loss: 0.8009\n",
      "Epoch 325/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7016 - loss: 0.8363\n",
      "Epoch 325: val_acc improved from 0.71760 to 0.71860, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7016 - loss: 0.8363 - val_acc: 0.7186 - val_loss: 0.8007\n",
      "Epoch 326/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6995 - loss: 0.8429\n",
      "Epoch 326: val_acc did not improve from 0.71860\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6995 - loss: 0.8429 - val_acc: 0.7161 - val_loss: 0.8084\n",
      "Epoch 327/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6981 - loss: 0.8424\n",
      "Epoch 327: val_acc did not improve from 0.71860\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6982 - loss: 0.8424 - val_acc: 0.7159 - val_loss: 0.8068\n",
      "Epoch 328/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7035 - loss: 0.8378\n",
      "Epoch 328: val_acc did not improve from 0.71860\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7035 - loss: 0.8378 - val_acc: 0.7174 - val_loss: 0.8025\n",
      "Epoch 329/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7022 - loss: 0.8389\n",
      "Epoch 329: val_acc did not improve from 0.71860\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7022 - loss: 0.8389 - val_acc: 0.7149 - val_loss: 0.8084\n",
      "Epoch 330/1000\n",
      "\u001b[1m1987/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7027 - loss: 0.8422\n",
      "Epoch 330: val_acc improved from 0.71860 to 0.71920, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7027 - loss: 0.8422 - val_acc: 0.7192 - val_loss: 0.7987\n",
      "Epoch 331/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7025 - loss: 0.8389\n",
      "Epoch 331: val_acc did not improve from 0.71920\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7025 - loss: 0.8389 - val_acc: 0.7160 - val_loss: 0.8040\n",
      "Epoch 332/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.6988 - loss: 0.8399\n",
      "Epoch 332: val_acc did not improve from 0.71920\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.6989 - loss: 0.8399 - val_acc: 0.7182 - val_loss: 0.7969\n",
      "Epoch 333/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7008 - loss: 0.8380\n",
      "Epoch 333: val_acc improved from 0.71920 to 0.71980, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7008 - loss: 0.8380 - val_acc: 0.7198 - val_loss: 0.7988\n",
      "Epoch 334/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7053 - loss: 0.8360\n",
      "Epoch 334: val_acc did not improve from 0.71980\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7053 - loss: 0.8360 - val_acc: 0.7196 - val_loss: 0.7954\n",
      "Epoch 335/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7034 - loss: 0.8303\n",
      "Epoch 335: val_acc did not improve from 0.71980\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7034 - loss: 0.8303 - val_acc: 0.7192 - val_loss: 0.7986\n",
      "Epoch 336/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7051 - loss: 0.8293\n",
      "Epoch 336: val_acc improved from 0.71980 to 0.72030, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7051 - loss: 0.8293 - val_acc: 0.7203 - val_loss: 0.7983\n",
      "Epoch 337/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7062 - loss: 0.8323\n",
      "Epoch 337: val_acc did not improve from 0.72030\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7062 - loss: 0.8323 - val_acc: 0.7182 - val_loss: 0.8012\n",
      "Epoch 338/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7071 - loss: 0.8298\n",
      "Epoch 338: val_acc improved from 0.72030 to 0.72250, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7071 - loss: 0.8297 - val_acc: 0.7225 - val_loss: 0.7931\n",
      "Epoch 339/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7046 - loss: 0.8297\n",
      "Epoch 339: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7046 - loss: 0.8297 - val_acc: 0.7183 - val_loss: 0.7965\n",
      "Epoch 340/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7086 - loss: 0.8248\n",
      "Epoch 340: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7086 - loss: 0.8248 - val_acc: 0.7183 - val_loss: 0.8018\n",
      "Epoch 341/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7032 - loss: 0.8335\n",
      "Epoch 341: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7032 - loss: 0.8334 - val_acc: 0.7179 - val_loss: 0.7994\n",
      "Epoch 342/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7076 - loss: 0.8249\n",
      "Epoch 342: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7076 - loss: 0.8248 - val_acc: 0.7195 - val_loss: 0.7971\n",
      "Epoch 343/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7079 - loss: 0.8223\n",
      "Epoch 343: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7079 - loss: 0.8223 - val_acc: 0.7208 - val_loss: 0.7926\n",
      "Epoch 344/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7066 - loss: 0.8291\n",
      "Epoch 344: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7066 - loss: 0.8291 - val_acc: 0.7196 - val_loss: 0.7932\n",
      "Epoch 345/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7082 - loss: 0.8245\n",
      "Epoch 345: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7082 - loss: 0.8245 - val_acc: 0.7202 - val_loss: 0.7940\n",
      "Epoch 346/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7041 - loss: 0.8291\n",
      "Epoch 346: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7041 - loss: 0.8291 - val_acc: 0.7190 - val_loss: 0.7984\n",
      "Epoch 347/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7056 - loss: 0.8218\n",
      "Epoch 347: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7056 - loss: 0.8218 - val_acc: 0.7202 - val_loss: 0.7928\n",
      "Epoch 348/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7093 - loss: 0.8171\n",
      "Epoch 348: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7093 - loss: 0.8171 - val_acc: 0.7207 - val_loss: 0.7898\n",
      "Epoch 349/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.7087 - loss: 0.8228\n",
      "Epoch 349: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7087 - loss: 0.8228 - val_acc: 0.7180 - val_loss: 0.7983\n",
      "Epoch 350/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7090 - loss: 0.8179\n",
      "Epoch 350: val_acc did not improve from 0.72250\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7090 - loss: 0.8179 - val_acc: 0.7212 - val_loss: 0.7935\n",
      "Epoch 351/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7112 - loss: 0.8166\n",
      "Epoch 351: val_acc improved from 0.72250 to 0.72290, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7112 - loss: 0.8166 - val_acc: 0.7229 - val_loss: 0.7848\n",
      "Epoch 352/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7046 - loss: 0.8253\n",
      "Epoch 352: val_acc improved from 0.72290 to 0.72370, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7046 - loss: 0.8253 - val_acc: 0.7237 - val_loss: 0.7849\n",
      "Epoch 353/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7108 - loss: 0.8211\n",
      "Epoch 353: val_acc did not improve from 0.72370\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7108 - loss: 0.8211 - val_acc: 0.7235 - val_loss: 0.7859\n",
      "Epoch 354/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7109 - loss: 0.8168\n",
      "Epoch 354: val_acc did not improve from 0.72370\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7109 - loss: 0.8168 - val_acc: 0.7199 - val_loss: 0.7954\n",
      "Epoch 355/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7110 - loss: 0.8164\n",
      "Epoch 355: val_acc improved from 0.72370 to 0.72380, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7110 - loss: 0.8164 - val_acc: 0.7238 - val_loss: 0.7886\n",
      "Epoch 356/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7125 - loss: 0.8176\n",
      "Epoch 356: val_acc did not improve from 0.72380\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7125 - loss: 0.8176 - val_acc: 0.7219 - val_loss: 0.7892\n",
      "Epoch 357/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7099 - loss: 0.8157\n",
      "Epoch 357: val_acc did not improve from 0.72380\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7099 - loss: 0.8156 - val_acc: 0.7222 - val_loss: 0.7872\n",
      "Epoch 358/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7106 - loss: 0.8173\n",
      "Epoch 358: val_acc did not improve from 0.72380\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7106 - loss: 0.8173 - val_acc: 0.7226 - val_loss: 0.7878\n",
      "Epoch 359/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7117 - loss: 0.8166\n",
      "Epoch 359: val_acc did not improve from 0.72380\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7117 - loss: 0.8166 - val_acc: 0.7226 - val_loss: 0.7847\n",
      "Epoch 360/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7098 - loss: 0.8149\n",
      "Epoch 360: val_acc did not improve from 0.72380\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7098 - loss: 0.8149 - val_acc: 0.7231 - val_loss: 0.7887\n",
      "Epoch 361/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7117 - loss: 0.8124\n",
      "Epoch 361: val_acc did not improve from 0.72380\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7117 - loss: 0.8124 - val_acc: 0.7237 - val_loss: 0.7829\n",
      "Epoch 362/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.7133 - loss: 0.8129\n",
      "Epoch 362: val_acc improved from 0.72380 to 0.72560, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7133 - loss: 0.8129 - val_acc: 0.7256 - val_loss: 0.7834\n",
      "Epoch 363/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7160 - loss: 0.8037\n",
      "Epoch 363: val_acc improved from 0.72560 to 0.72710, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7160 - loss: 0.8037 - val_acc: 0.7271 - val_loss: 0.7775\n",
      "Epoch 364/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7112 - loss: 0.8126\n",
      "Epoch 364: val_acc did not improve from 0.72710\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7112 - loss: 0.8126 - val_acc: 0.7259 - val_loss: 0.7755\n",
      "Epoch 365/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7127 - loss: 0.8095\n",
      "Epoch 365: val_acc did not improve from 0.72710\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7127 - loss: 0.8095 - val_acc: 0.7245 - val_loss: 0.7835\n",
      "Epoch 366/1000\n",
      "\u001b[1m1987/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7121 - loss: 0.8144\n",
      "Epoch 366: val_acc did not improve from 0.72710\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7121 - loss: 0.8144 - val_acc: 0.7233 - val_loss: 0.7842\n",
      "Epoch 367/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7119 - loss: 0.8128\n",
      "Epoch 367: val_acc did not improve from 0.72710\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7119 - loss: 0.8128 - val_acc: 0.7263 - val_loss: 0.7810\n",
      "Epoch 368/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7086 - loss: 0.8080\n",
      "Epoch 368: val_acc did not improve from 0.72710\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7086 - loss: 0.8080 - val_acc: 0.7259 - val_loss: 0.7788\n",
      "Epoch 369/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7131 - loss: 0.8090\n",
      "Epoch 369: val_acc improved from 0.72710 to 0.72730, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7131 - loss: 0.8090 - val_acc: 0.7273 - val_loss: 0.7759\n",
      "Epoch 370/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7092 - loss: 0.8099\n",
      "Epoch 370: val_acc improved from 0.72730 to 0.72740, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7092 - loss: 0.8099 - val_acc: 0.7274 - val_loss: 0.7736\n",
      "Epoch 371/1000\n",
      "\u001b[1m1989/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7108 - loss: 0.8077\n",
      "Epoch 371: val_acc did not improve from 0.72740\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7108 - loss: 0.8076 - val_acc: 0.7247 - val_loss: 0.7794\n",
      "Epoch 372/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7164 - loss: 0.7999\n",
      "Epoch 372: val_acc improved from 0.72740 to 0.72830, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7164 - loss: 0.7999 - val_acc: 0.7283 - val_loss: 0.7747\n",
      "Epoch 373/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7180 - loss: 0.8020\n",
      "Epoch 373: val_acc did not improve from 0.72830\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7180 - loss: 0.8020 - val_acc: 0.7265 - val_loss: 0.7793\n",
      "Epoch 374/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7157 - loss: 0.8038\n",
      "Epoch 374: val_acc did not improve from 0.72830\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7157 - loss: 0.8038 - val_acc: 0.7275 - val_loss: 0.7741\n",
      "Epoch 375/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7171 - loss: 0.8045\n",
      "Epoch 375: val_acc did not improve from 0.72830\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7171 - loss: 0.8045 - val_acc: 0.7254 - val_loss: 0.7833\n",
      "Epoch 376/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7165 - loss: 0.8009\n",
      "Epoch 376: val_acc did not improve from 0.72830\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7165 - loss: 0.8009 - val_acc: 0.7283 - val_loss: 0.7746\n",
      "Epoch 377/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7155 - loss: 0.8015\n",
      "Epoch 377: val_acc improved from 0.72830 to 0.72870, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7155 - loss: 0.8015 - val_acc: 0.7287 - val_loss: 0.7666\n",
      "Epoch 378/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7164 - loss: 0.7990\n",
      "Epoch 378: val_acc improved from 0.72870 to 0.72910, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7164 - loss: 0.7990 - val_acc: 0.7291 - val_loss: 0.7768\n",
      "Epoch 379/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7192 - loss: 0.8003\n",
      "Epoch 379: val_acc did not improve from 0.72910\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7192 - loss: 0.8003 - val_acc: 0.7282 - val_loss: 0.7757\n",
      "Epoch 380/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7138 - loss: 0.7970\n",
      "Epoch 380: val_acc improved from 0.72910 to 0.73000, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7138 - loss: 0.7970 - val_acc: 0.7300 - val_loss: 0.7713\n",
      "Epoch 381/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7159 - loss: 0.8035\n",
      "Epoch 381: val_acc improved from 0.73000 to 0.73100, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7159 - loss: 0.8035 - val_acc: 0.7310 - val_loss: 0.7668\n",
      "Epoch 382/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7168 - loss: 0.7955\n",
      "Epoch 382: val_acc did not improve from 0.73100\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7168 - loss: 0.7955 - val_acc: 0.7273 - val_loss: 0.7771\n",
      "Epoch 383/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7193 - loss: 0.7926\n",
      "Epoch 383: val_acc did not improve from 0.73100\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7193 - loss: 0.7926 - val_acc: 0.7269 - val_loss: 0.7719\n",
      "Epoch 384/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7174 - loss: 0.7986\n",
      "Epoch 384: val_acc did not improve from 0.73100\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7174 - loss: 0.7986 - val_acc: 0.7276 - val_loss: 0.7703\n",
      "Epoch 385/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7162 - loss: 0.7993\n",
      "Epoch 385: val_acc did not improve from 0.73100\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7162 - loss: 0.7993 - val_acc: 0.7297 - val_loss: 0.7712\n",
      "Epoch 386/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7187 - loss: 0.7950\n",
      "Epoch 386: val_acc did not improve from 0.73100\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7187 - loss: 0.7950 - val_acc: 0.7310 - val_loss: 0.7666\n",
      "Epoch 387/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7202 - loss: 0.7902\n",
      "Epoch 387: val_acc improved from 0.73100 to 0.73130, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7202 - loss: 0.7902 - val_acc: 0.7313 - val_loss: 0.7630\n",
      "Epoch 388/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7218 - loss: 0.7902\n",
      "Epoch 388: val_acc improved from 0.73130 to 0.73200, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7218 - loss: 0.7902 - val_acc: 0.7320 - val_loss: 0.7616\n",
      "Epoch 389/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7177 - loss: 0.7949\n",
      "Epoch 389: val_acc did not improve from 0.73200\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7177 - loss: 0.7949 - val_acc: 0.7299 - val_loss: 0.7660\n",
      "Epoch 390/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7134 - loss: 0.8010\n",
      "Epoch 390: val_acc did not improve from 0.73200\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7134 - loss: 0.8009 - val_acc: 0.7287 - val_loss: 0.7709\n",
      "Epoch 391/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7175 - loss: 0.7917\n",
      "Epoch 391: val_acc did not improve from 0.73200\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7175 - loss: 0.7917 - val_acc: 0.7306 - val_loss: 0.7652\n",
      "Epoch 392/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7222 - loss: 0.7902\n",
      "Epoch 392: val_acc did not improve from 0.73200\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7222 - loss: 0.7902 - val_acc: 0.7295 - val_loss: 0.7706\n",
      "Epoch 393/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7171 - loss: 0.7958\n",
      "Epoch 393: val_acc did not improve from 0.73200\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7171 - loss: 0.7958 - val_acc: 0.7307 - val_loss: 0.7646\n",
      "Epoch 394/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.7196 - loss: 0.7851\n",
      "Epoch 394: val_acc improved from 0.73200 to 0.73270, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7196 - loss: 0.7851 - val_acc: 0.7327 - val_loss: 0.7605\n",
      "Epoch 395/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.7184 - loss: 0.7945\n",
      "Epoch 395: val_acc did not improve from 0.73270\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7184 - loss: 0.7945 - val_acc: 0.7308 - val_loss: 0.7648\n",
      "Epoch 396/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.7195 - loss: 0.7858\n",
      "Epoch 396: val_acc did not improve from 0.73270\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - acc: 0.7195 - loss: 0.7858 - val_acc: 0.7300 - val_loss: 0.7620\n",
      "Epoch 397/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7164 - loss: 0.7947\n",
      "Epoch 397: val_acc did not improve from 0.73270\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7164 - loss: 0.7947 - val_acc: 0.7281 - val_loss: 0.7701\n",
      "Epoch 398/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7226 - loss: 0.7826\n",
      "Epoch 398: val_acc improved from 0.73270 to 0.73290, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7226 - loss: 0.7826 - val_acc: 0.7329 - val_loss: 0.7588\n",
      "Epoch 399/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7189 - loss: 0.7904\n",
      "Epoch 399: val_acc did not improve from 0.73290\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7189 - loss: 0.7904 - val_acc: 0.7308 - val_loss: 0.7637\n",
      "Epoch 400/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7203 - loss: 0.7894\n",
      "Epoch 400: val_acc did not improve from 0.73290\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7203 - loss: 0.7894 - val_acc: 0.7310 - val_loss: 0.7635\n",
      "Epoch 401/1000\n",
      "\u001b[1m1997/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7211 - loss: 0.7868\n",
      "Epoch 401: val_acc did not improve from 0.73290\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7211 - loss: 0.7867 - val_acc: 0.7315 - val_loss: 0.7594\n",
      "Epoch 402/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7200 - loss: 0.7861\n",
      "Epoch 402: val_acc improved from 0.73290 to 0.73400, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7201 - loss: 0.7861 - val_acc: 0.7340 - val_loss: 0.7566\n",
      "Epoch 403/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7197 - loss: 0.7934\n",
      "Epoch 403: val_acc did not improve from 0.73400\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7197 - loss: 0.7934 - val_acc: 0.7333 - val_loss: 0.7606\n",
      "Epoch 404/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7203 - loss: 0.7914\n",
      "Epoch 404: val_acc improved from 0.73400 to 0.73490, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7203 - loss: 0.7914 - val_acc: 0.7349 - val_loss: 0.7532\n",
      "Epoch 405/1000\n",
      "\u001b[1m1996/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7189 - loss: 0.7871\n",
      "Epoch 405: val_acc did not improve from 0.73490\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7189 - loss: 0.7871 - val_acc: 0.7345 - val_loss: 0.7553\n",
      "Epoch 406/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7246 - loss: 0.7832\n",
      "Epoch 406: val_acc did not improve from 0.73490\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7246 - loss: 0.7832 - val_acc: 0.7303 - val_loss: 0.7575\n",
      "Epoch 407/1000\n",
      "\u001b[1m1988/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7262 - loss: 0.7744\n",
      "Epoch 407: val_acc did not improve from 0.73490\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7262 - loss: 0.7744 - val_acc: 0.7334 - val_loss: 0.7576\n",
      "Epoch 408/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7245 - loss: 0.7752\n",
      "Epoch 408: val_acc did not improve from 0.73490\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7245 - loss: 0.7752 - val_acc: 0.7344 - val_loss: 0.7540\n",
      "Epoch 409/1000\n",
      "\u001b[1m1998/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7262 - loss: 0.7758\n",
      "Epoch 409: val_acc did not improve from 0.73490\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7262 - loss: 0.7758 - val_acc: 0.7327 - val_loss: 0.7562\n",
      "Epoch 410/1000\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7231 - loss: 0.7769\n",
      "Epoch 410: val_acc improved from 0.73490 to 0.73500, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7231 - loss: 0.7769 - val_acc: 0.7350 - val_loss: 0.7564\n",
      "Epoch 411/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7264 - loss: 0.7745\n",
      "Epoch 411: val_acc improved from 0.73500 to 0.73530, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7263 - loss: 0.7745 - val_acc: 0.7353 - val_loss: 0.7510\n",
      "Epoch 412/1000\n",
      "\u001b[1m1990/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7259 - loss: 0.7748\n",
      "Epoch 412: val_acc did not improve from 0.73530\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7259 - loss: 0.7748 - val_acc: 0.7338 - val_loss: 0.7594\n",
      "Epoch 413/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7260 - loss: 0.7798\n",
      "Epoch 413: val_acc improved from 0.73530 to 0.73600, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7259 - loss: 0.7798 - val_acc: 0.7360 - val_loss: 0.7517\n",
      "Epoch 414/1000\n",
      "\u001b[1m1993/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.7244 - loss: 0.7741\n",
      "Epoch 414: val_acc did not improve from 0.73600\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - acc: 0.7244 - loss: 0.7741 - val_acc: 0.7327 - val_loss: 0.7584\n",
      "Epoch 415/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.7264 - loss: 0.7697\n",
      "Epoch 415: val_acc did not improve from 0.73600\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - acc: 0.7264 - loss: 0.7697 - val_acc: 0.7319 - val_loss: 0.7570\n",
      "Epoch 416/1000\n",
      "\u001b[1m1999/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.7255 - loss: 0.7739\n",
      "Epoch 416: val_acc did not improve from 0.73600\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - acc: 0.7255 - loss: 0.7739 - val_acc: 0.7299 - val_loss: 0.7647\n",
      "Epoch 417/1000\n",
      "\u001b[1m1994/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.7277 - loss: 0.7704\n",
      "Epoch 417: val_acc did not improve from 0.73600\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - acc: 0.7277 - loss: 0.7704 - val_acc: 0.7331 - val_loss: 0.7558\n",
      "Epoch 418/1000\n",
      "\u001b[1m1995/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.7303 - loss: 0.7697\n",
      "Epoch 418: val_acc did not improve from 0.73600\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - acc: 0.7303 - loss: 0.7697 - val_acc: 0.7349 - val_loss: 0.7525\n",
      "Epoch 419/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7271 - loss: 0.7673\n",
      "Epoch 419: val_acc improved from 0.73600 to 0.73630, saving model to modelS_checkpoint_adam.keras\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7271 - loss: 0.7673 - val_acc: 0.7363 - val_loss: 0.7536\n",
      "Epoch 420/1000\n",
      "\u001b[1m1992/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7265 - loss: 0.7730\n",
      "Epoch 420: val_acc did not improve from 0.73630\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7266 - loss: 0.7730 - val_acc: 0.7338 - val_loss: 0.7545\n",
      "Epoch 421/1000\n",
      "\u001b[1m1991/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 0.7246 - loss: 0.7722\n",
      "Epoch 421: val_acc did not improve from 0.73630\n",
      "\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - acc: 0.7246 - loss: 0.7722 - val_acc: 0.7343 - val_loss: 0.7588\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,epochs=1000,validation_data=validation_dataset,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "loaded_model = tf.keras.models.load_model('modelS_checkpoint_adam.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">511,136</span> (1.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m511,136\u001b[0m (1.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,378</span> (665.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m170,378\u001b[0m (665.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">340,758</span> (1.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m340,758\u001b[0m (1.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - acc: 0.7345 - loss: 0.7498\n",
      "val_acc: 0.736299991607666\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = loaded_model.evaluate(validation_dataset)\n",
    "print('val_acc:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_result (result):\n",
    "    for i in range(10):\n",
    "        res = result[0][i].round()\n",
    "        if res == 1:\n",
    "            match i:\n",
    "                case 0:\n",
    "                    print(\"Airplane\")\n",
    "                case 1:\n",
    "                    print(\"Automobile\")\n",
    "                case 2:\n",
    "                    print(\"Bird\")\n",
    "                case 3:\n",
    "                    print(\"Cat\")\n",
    "                case 4:\n",
    "                    print(\"Deer\")\n",
    "                case 5:\n",
    "                    print(\"Dog\")\n",
    "                case 6:\n",
    "                    print(\"Frog\")\n",
    "                case 7:\n",
    "                    print(\"Horse\")\n",
    "                case 8:\n",
    "                    print(\"Ship\")\n",
    "                case 9:\n",
    "                    print(\"Truck\")\n",
    "            return\n",
    "\n",
    "    print(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 897ms/step\n",
      "Result:  [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "Frog\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "img = tf.keras.preprocessing.image.load_img('train/006_frog/alytes_obstetricans_s_000028.png', target_size=(32, 32), interpolation='bilinear')\n",
    "print(img.size)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "print(img_array.shape)\n",
    "result = model.predict(img_array)\n",
    "print(\"Result: \", result.round())\n",
    "class_result(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
