{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 08:09:36.233643: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-09 08:09:37.100192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training airplane images: 3995\n",
      "total training automobile images: 4026\n",
      "total training bird images: 3968\n",
      "total training cat images: 3984\n",
      "total training deer images: 4001\n",
      "total training dog images: 4063\n",
      "total training frog images: 3970\n",
      "total training horse images: 3999\n",
      "total training ship images: 3975\n",
      "total training truck images: 4019\n",
      "total validation airplane images: 1005\n",
      "total validation automobile images: 974\n",
      "total validation bird images: 1032\n",
      "total validation cat images: 1016\n",
      "total validation deer images: 999\n",
      "total validation dog images: 937\n",
      "total validation frog images: 1030\n",
      "total validation horse images: 1001\n",
      "total validation ship images: 1025\n",
      "total validation truck images: 981\n",
      "total test airplane images: 1000\n",
      "total test automobile images: 1000\n",
      "total test bird images: 1000\n",
      "total test cat images: 1000\n",
      "total test deer images: 1000\n",
      "total test dog images: 1000\n",
      "total test frog images: 1000\n",
      "total test horse images: 1000\n",
      "total test ship images: 1000\n",
      "total test truck images: 1000\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # or any {‘0’, ‘1’, ‘2’}\n",
    "train_dir = 'train'\n",
    "validation_dir = 'validation'\n",
    "test_dir = 'test'\n",
    "train_airplane_dir = 'train/000_airplane'\n",
    "train_automobile_dir = 'train/001_automobile'\n",
    "train_bird_dir = 'train/002_bird'\n",
    "train_cat_dir = 'train/003_cat'\n",
    "train_deer_dir = 'train/004_deer'\n",
    "train_dog_dir = 'train/005_dog'\n",
    "train_frog_dir = 'train/006_frog'\n",
    "train_horse_dir = 'train/007_horse'\n",
    "train_ship_dir = 'train/008_ship'\n",
    "train_truck_dir = 'train/009_truck'\n",
    "\n",
    "validation_airplane_dir = 'validation/000_airplane'\n",
    "validation_automobile_dir = 'validation/001_automobile'\n",
    "validation_bird_dir = 'validation/002_bird'\n",
    "validation_cat_dir = 'validation/003_cat'\n",
    "validation_deer_dir = 'validation/004_deer'\n",
    "validation_dog_dir = 'validation/005_dog'\n",
    "validation_frog_dir = 'validation/006_frog'\n",
    "validation_horse_dir = 'validation/007_horse'\n",
    "validation_ship_dir = 'validation/008_ship'\n",
    "validation_truck_dir = 'validation/009_truck'\n",
    "\n",
    "test_airplane_dir = 'test/000_airplane'\n",
    "test_automobile_dir = 'test/001_automobile'\n",
    "test_bird_dir = 'test/002_bird'\n",
    "test_cat_dir = 'test/003_cat'\n",
    "test_deer_dir = 'test/004_deer'\n",
    "test_dog_dir = 'test/005_dog'\n",
    "test_frog_dir = 'test/006_frog'\n",
    "test_horse_dir = 'test/007_horse'\n",
    "test_ship_dir = 'test/008_ship'\n",
    "test_truck_dir = 'test/009_truck'\n",
    "\n",
    "\n",
    "print('total training airplane images:', len(os.listdir(train_airplane_dir)))\n",
    "print('total training automobile images:', len(os.listdir(train_automobile_dir)))\n",
    "print('total training bird images:', len(os.listdir(train_bird_dir)))\n",
    "print('total training cat images:', len(os.listdir(train_cat_dir)))\n",
    "print('total training deer images:', len(os.listdir(train_deer_dir)))\n",
    "print('total training dog images:', len(os.listdir(train_dog_dir)))\n",
    "print('total training frog images:', len(os.listdir(train_frog_dir)))\n",
    "print('total training horse images:', len(os.listdir(train_horse_dir)))\n",
    "print('total training ship images:', len(os.listdir(train_ship_dir)))\n",
    "print('total training truck images:', len(os.listdir(train_truck_dir)))\n",
    "\n",
    "print('total validation airplane images:', len(os.listdir(validation_airplane_dir)))\n",
    "print('total validation automobile images:', len(os.listdir(validation_automobile_dir)))\n",
    "print('total validation bird images:', len(os.listdir(validation_bird_dir)))\n",
    "print('total validation cat images:', len(os.listdir(validation_cat_dir)))\n",
    "print('total validation deer images:', len(os.listdir(validation_deer_dir)))\n",
    "print('total validation dog images:', len(os.listdir(validation_dog_dir)))\n",
    "print('total validation frog images:', len(os.listdir(validation_frog_dir)))\n",
    "print('total validation horse images:', len(os.listdir(validation_horse_dir)))\n",
    "print('total validation ship images:', len(os.listdir(validation_ship_dir)))\n",
    "print('total validation truck images:', len(os.listdir(validation_truck_dir)))\n",
    "\n",
    "print('total test airplane images:', len(os.listdir(test_airplane_dir)))\n",
    "print('total test automobile images:', len(os.listdir(test_automobile_dir)))\n",
    "print('total test bird images:', len(os.listdir(test_bird_dir)))\n",
    "print('total test cat images:', len(os.listdir(test_cat_dir)))\n",
    "print('total test deer images:', len(os.listdir(test_deer_dir)))\n",
    "print('total test dog images:', len(os.listdir(test_dog_dir)))\n",
    "print('total test frog images:', len(os.listdir(test_frog_dir)))\n",
    "print('total test horse images:', len(os.listdir(test_horse_dir)))\n",
    "print('total test ship images:', len(os.listdir(test_ship_dir)))\n",
    "print('total test truck images:', len(os.listdir(test_truck_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "IMG_SIZE = 150\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 08:29:11.920926: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 08:29:12.173220: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 08:29:12.173280: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 08:29:12.179289: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 08:29:12.179369: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 08:29:12.179394: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 08:29:12.379493: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 08:29:12.379850: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 08:29:12.379893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-09 08:29:12.380274: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-09 08:29:12.380474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "[\n",
    "layers.RandomFlip(\"horizontal\"),\n",
    "layers.RandomRotation(0.1),\n",
    "layers.RandomZoom(0.2),\n",
    "]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for images, _ in train_dataset(1):\n",
    "    for i in range(4):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(2,2,i+1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import models\n",
    "\n",
    "inputs= keras.Input(shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "x=data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26064/2976033932.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history=model.fit(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model()\n",
    "\n",
    "\n",
    "\n",
    "val_loss, val_acc = model.evaluate(validation_dataset)\n",
    "print('val_acc:', val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
